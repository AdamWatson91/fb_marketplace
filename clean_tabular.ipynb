{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import json\n",
    "from pandas_profiling import ProfileReport\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import string\n",
    "\n",
    "# Get database connection credentials\n",
    "with open(os.path.join(os.getcwd(),'fb_marketplace_conn.json'), mode='r') as f:\n",
    "    database_dict = json.load(f)\n",
    "# Password for the database\n",
    "RDS_pass = 'aicore2022!'\n",
    "# Create engine to connect to database\n",
    "engine = create_engine(f\"{database_dict['DATABASE_TYPE']}+{database_dict['DBAPI']}://{database_dict['USER']}:{RDS_pass}@{database_dict['HOST']}:{database_dict['PORT']}/{database_dict['DATABASE']}\")\n",
    "# Import the tables as DataFrame\n",
    "products = pd.read_sql('products', engine)\n",
    "images = pd.read_sql('images', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2021/06/generate-reports-using-pandas-profiling-deploy-using-streamlit/products.info(verbose=True)\n",
    "products.head()\n",
    "prof = ProfileReport(products)\n",
    "prof.to_file(output_file='products.html')\n",
    "\n",
    "images.info(verbose=True)\n",
    "images.head()\n",
    "prof = ProfileReport(images)\n",
    "prof.to_file(output_file='images.html')\n",
    "\n",
    "# Pandas profiling outcome\n",
    "    # # Product name 94.7 unique and mean lenght is 76 characters\n",
    "    # # Category - 11.6% N/A and 436 distinact categories \n",
    "    # # product_desciprtion 935 N/A, mostly unique\n",
    "    # # price 935 N/A  (so it seems N?As are acroos the board, but might not be) price is string\n",
    "    # # url not missing - interesting as this might help get product name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "products_numeric_cols = products.select_dtypes(include=['number']).columns\n",
    "print(products_numeric_cols)\n",
    "\n",
    "products_non_numeric_cols = products.select_dtypes(exclude=['number']).columns\n",
    "print(products_non_numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count number of products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of products\n",
    "print(f'The number of products in the database is {len(products)}')\n",
    "# Are all the products actually unique?\n",
    "unique_products = products['id'].nunique()\n",
    "print(f'The number of unique products is {unique_products}')\n",
    "# Count number of images\n",
    "print(f'The number of images in the database is {len(images)}')\n",
    "# Are all the images actually unique?\n",
    "unique_images = images['id'].nunique()\n",
    "print(f'The number of unique images is {unique_images}')\n",
    "# Count unique create_date to see if it is all the same\n",
    "create_time_unique = products['create_time'].nunique()\n",
    "print(f'The number of unique create_times is {create_time_unique}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good site https://www.justintodata.com/data-cleaning-techniques-python-guide/\n",
    "# Get simpliest form to name a product\n",
    "    # Extract just product name from product name\n",
    "    # Could get the second from last index from url - seems the most complete version of the description - Could take hirearchy approach , name, url, description\n",
    "\n",
    "# plt.figure(figsize=(10,8))\n",
    "# Heat map to show missing data across colunms\n",
    "# It shows that N/A values are across specific colunmns and that by removing these we would not lose any useful information\n",
    "# colours = ['#000099', '#ffff00'] # specify colours: yellow - missing. blue - not missing\n",
    "# sns.heatmap(products == 'N/A', cmap=sns.color_palette(colours))\n",
    "# Remove N/A rows\n",
    "# This method removes the rows completely from products, even when assigning to var\n",
    "# products_na_removed = products.drop(products[products['category'] == 'N/A'].index, inplace=True)\n",
    "# This methods filters products and can assign to the variable so that the products full dataframe remains\n",
    "products_na_removed = products.loc[products['category'] != 'N/A']\n",
    "\n",
    "# Make location useful\n",
    "# Split by , to get the city and county\n",
    "# Consider using this for mapping\n",
    "# Remove the location field once split\n",
    "products_na_removed[['city_town', 'county']] = products_na_removed['location'].str.split(',', expand=True)\n",
    "products_na_removed.drop('location', axis=1, inplace=True)\n",
    "\n",
    "# Make the price field useable for summary statistics and predictions   \n",
    "    # Convert price to a float without £ symbol, and rename pcolunm name t state currency (£)\n",
    "    # May convert to bins and even give categorical low, medium, high\n",
    "products_na_removed[['price_gbp']] = products_na_removed[['price']].replace('[\\£,]', '', regex=True).astype(float)\n",
    "products_na_removed.drop('price', axis=1, inplace=True)\n",
    "\n",
    "# Extract the various categories for products\n",
    "\n",
    "    # Check which level provides a sensible number of categories by looking and NaN fields\n",
    "        # Should be not too many or not too little and not too blank\n",
    "# Find the max count of catgeories using '/' as the delimiter\n",
    "max_categories = products_na_removed['category'].str.count('/').max()\n",
    "# split by / and create multiple category fields\n",
    "sub_categories = products_na_removed['category'].str.split('/', expand=True).reindex(range(max_categories), axis=1).add_prefix('sub_cat_')\n",
    "# join the sub catgeories to the original dataframe and rename\n",
    "products_na_removed = pd.concat([products_na_removed,sub_categories], axis=1)\n",
    "# Remove original catgeory field\n",
    "products_na_removed.drop('category', axis=1, inplace=True)\n",
    "products_na_removed.head()\n",
    "\n",
    "# #Remove stopwords, punctuation and numbers\n",
    "# text2 = [remove_stopwords(x)\\\n",
    "#         .translate(str.maketrans('','',string.punctuation))\\\n",
    "#         .translate(str.maketrans('','',string.digits))\\\n",
    "#         for x in products_na_removed[['product_description']]]\n",
    "# print(text2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ad305deca811d2df6c57b148dec1e835d783e41823b85ed7281e336135b66d8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('fb_marketplace')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
