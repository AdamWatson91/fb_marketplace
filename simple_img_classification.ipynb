{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from clean_images import ImageClense\n",
    "from clean_tabular import TabularCleanse\n",
    "\n",
    "tabular_cleanse = TabularCleanse('fb_marketplace_conn.json', 'aicore2022!')\n",
    "links =  pd.read_csv('/home/adamw/Documents/AiCore/fb_marketplace/images_fb/Links.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare list of products to include in classficiation\n",
    "###### This is based on the same data included in the tabular classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                          243809c0-9cfc-4486-ad12-3b7a16605ba91c58d3f9-8...\n",
       "price_gbp                                                                            736256.0\n",
       "long                                                                            344014.976773\n",
       "lat                                                                             -22414.651779\n",
       "cat_0__Appliances                                                                         494\n",
       "cat_0__Baby & Kids Stuff                                                                  392\n",
       "cat_0__Clothes, Footwear & Accessories                                                    368\n",
       "cat_0__Computers & Software                                                               547\n",
       "cat_0__DIY Tools & Materials                                                              505\n",
       "cat_0__Health & Beauty                                                                    566\n",
       "cat_0__Home & Garden                                                                      799\n",
       "cat_0__Music, Films, Books & Games                                                        590\n",
       "cat_0__Office Furniture & Equipment                                                       542\n",
       "cat_0__Other Goods                                                                        494\n",
       "cat_0__Phones, Mobile Phones & Telecoms                                                   400\n",
       "cat_0__Sports, Leisure & Travel                                                           431\n",
       "cat_0__Video Games & Consoles                                                             500\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = pd.read_pickle('final_cleaned_products.pkl')\n",
    "products = products.dropna(subset='long')\n",
    "products = tabular_cleanse.remove_rows_conditonal(products, 'price_gbp', 1000.00, '<')\n",
    "products.drop(['location'], axis=1, inplace=True)\n",
    "# Drop the cat0 fields to test the model\n",
    "# Consider that dummy encodign has been applied and therefore on of the clasesses is missing.\n",
    "# https://machinelearningmastery.com/types-of-classification-in-machine-learning/\n",
    "#https://machinelearningmastery.com/discrete-probability-distributions-for-machine-learning/\n",
    "products = products[products.columns.drop(list(products.filter(regex='cat_1')))]\n",
    "# This puts category appliances back in as it was removed when cleaning the data using dummy encoding. This was used because i did not want to run the geocoder again due to un time.\n",
    "categories = list(products.filter(regex='cat_0'))\n",
    "products['cat_0__Appliances'] = np.where(products[categories].sum(axis=1) == 0, 1, 0)\n",
    "Applicances = products.pop('cat_0__Appliances')\n",
    "products.insert(4,'cat_0__Appliances', Applicances)\n",
    "# k-Nearest Neighbors.\n",
    "# Decision Trees.\n",
    "# Naive Bayes.\n",
    "# Random Forest.\n",
    "# Gradient Boosting.\n",
    "products.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the tabular data for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adamw/Documents/AiCore/fb_marketplace/clean_tabular.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[new_field_names] = data[field_to_split].str.split(split_by, expand=True)\n",
      "/home/adamw/Documents/AiCore/fb_marketplace/clean_tabular.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[new_field_names] = data[field_to_split].str.split(split_by, expand=True)\n",
      "/home/adamw/Documents/AiCore/fb_marketplace/clean_tabular.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[new_field_name] = data[field_to_convert].replace(replace_value, '', regex=True).astype(float)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>price_gbp</th>\n",
       "      <th>sub_cat_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>243809c0-9cfc-4486-ad12-3b7a16605ba9</td>\n",
       "      <td>Wokingham, Berkshire</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1c58d3f9-8b93-47ea-9415-204fcc2a22e6</td>\n",
       "      <td>Inverness, Highland</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>860673f1-57f6-47ba-8d2f-13f9e05b8f9a</td>\n",
       "      <td>Skegness, Lincolnshire</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59948726-29be-4b35-ade5-bb2fd7331856</td>\n",
       "      <td>Radstock, Somerset</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16dbc860-696e-4cda-93f6-4dd4926573fb</td>\n",
       "      <td>Delph, Manchester</td>\n",
       "      <td>450.0</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8085</th>\n",
       "      <td>c4148656-78a9-4f3e-b393-134fdc5ef900</td>\n",
       "      <td>Acocks Green, West Midlands</td>\n",
       "      <td>260.0</td>\n",
       "      <td>Video Games &amp; Consoles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8086</th>\n",
       "      <td>564e3411-768d-4250-a624-b119d696f103</td>\n",
       "      <td>Acocks Green, West Midlands</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Video Games &amp; Consoles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8088</th>\n",
       "      <td>2b0a652b-46a2-4297-b619-5efeeb222787</td>\n",
       "      <td>Montrose, Angus</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Video Games &amp; Consoles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8089</th>\n",
       "      <td>719fd40a-870e-4144-b324-55dff2e66fb4</td>\n",
       "      <td>Carrickfergus, County Antrim</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Video Games &amp; Consoles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8090</th>\n",
       "      <td>86d1806b-5575-4a7e-9160-f24f12be6c95</td>\n",
       "      <td>Poole, Dorset</td>\n",
       "      <td>450.0</td>\n",
       "      <td>Video Games &amp; Consoles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6628 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id                      location  \\\n",
       "1     243809c0-9cfc-4486-ad12-3b7a16605ba9          Wokingham, Berkshire   \n",
       "2     1c58d3f9-8b93-47ea-9415-204fcc2a22e6           Inverness, Highland   \n",
       "3     860673f1-57f6-47ba-8d2f-13f9e05b8f9a        Skegness, Lincolnshire   \n",
       "4     59948726-29be-4b35-ade5-bb2fd7331856            Radstock, Somerset   \n",
       "5     16dbc860-696e-4cda-93f6-4dd4926573fb             Delph, Manchester   \n",
       "...                                    ...                           ...   \n",
       "8085  c4148656-78a9-4f3e-b393-134fdc5ef900   Acocks Green, West Midlands   \n",
       "8086  564e3411-768d-4250-a624-b119d696f103   Acocks Green, West Midlands   \n",
       "8088  2b0a652b-46a2-4297-b619-5efeeb222787               Montrose, Angus   \n",
       "8089  719fd40a-870e-4144-b324-55dff2e66fb4  Carrickfergus, County Antrim   \n",
       "8090  86d1806b-5575-4a7e-9160-f24f12be6c95                 Poole, Dorset   \n",
       "\n",
       "      price_gbp                sub_cat_0  \n",
       "1           5.0           Home & Garden   \n",
       "2          20.0           Home & Garden   \n",
       "3          20.0           Home & Garden   \n",
       "4         115.0           Home & Garden   \n",
       "5         450.0           Home & Garden   \n",
       "...         ...                      ...  \n",
       "8085      260.0  Video Games & Consoles   \n",
       "8086      235.0  Video Games & Consoles   \n",
       "8088      250.0  Video Games & Consoles   \n",
       "8089       30.0  Video Games & Consoles   \n",
       "8090      450.0  Video Games & Consoles   \n",
       "\n",
       "[6628 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanse = TabularCleanse('fb_marketplace_conn.json', 'aicore2022!')\n",
    "products = cleanse.get_data_table('products')\n",
    "# cleanse.data_profile_report(products, 'products.html')\n",
    "cleaning_products = cleanse.remove_rows_conditonal(products, 'category', 'N/A', '!=')\n",
    "cleaning_products = cleanse.split_df_value(cleaning_products, 'location', ',', ['local_area', 'city'])\n",
    "cleaning_products = cleanse.convert_str_float(cleaning_products, 'price_gbp', 'price', '[\\Â£,]')\n",
    "cleaning_products = cleanse.remove_rows_conditonal(cleaning_products, 'price_gbp', 1000.00, '<')\n",
    "cleaning_products = cleanse.dynamic_split_df_value(cleaning_products, 'category', '/', True, 'sub_cat_')\n",
    "cleaning_products = cleanse.manual_split_df_value(cleaning_products, 'product_name', 'product_name', '|', 1)\n",
    "cleaning_products = cleaning_products.dropna(subset=['city'])\n",
    "cleaning_products.drop(['product_name', 'product_description', 'price', 'create_time', 'category', 'local_area','sub_cat_1','sub_cat_2', 'sub_cat_3', 'sub_cat_4', 'page_id', 'city'], axis=1, inplace=True)\n",
    "\n",
    "cleaning_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_cat_0\n",
      "Appliances                           494\n",
      "Baby & Kids Stuff                    392\n",
      "Clothes, Footwear & Accessories      368\n",
      "Computers & Software                 547\n",
      "DIY Tools & Materials                505\n",
      "Health & Beauty                      566\n",
      "Home & Garden                        799\n",
      "Music, Films, Books & Games          590\n",
      "Office Furniture & Equipment         542\n",
      "Other Goods                          494\n",
      "Phones, Mobile Phones & Telecoms     400\n",
      "Sports, Leisure & Travel             431\n",
      "Video Games & Consoles               500\n",
      "Name: sub_cat_0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Using groupby() and count()\n",
    "df2 = cleaning_products.groupby(['sub_cat_0'])['sub_cat_0'].count()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop more outliers for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_gbp</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>cat_0__Baby &amp; Kids Stuff</th>\n",
       "      <th>cat_0__Clothes, Footwear &amp; Accessories</th>\n",
       "      <th>cat_0__Computers &amp; Software</th>\n",
       "      <th>cat_0__DIY Tools &amp; Materials</th>\n",
       "      <th>cat_0__Health &amp; Beauty</th>\n",
       "      <th>cat_0__Home &amp; Garden</th>\n",
       "      <th>...</th>\n",
       "      <th>cat_1__ Washer Dryers</th>\n",
       "      <th>cat_1__ Washing Machines</th>\n",
       "      <th>cat_1__ Watches</th>\n",
       "      <th>cat_1__ Water Sports</th>\n",
       "      <th>cat_1__ Wedding Clothes &amp; Accessories</th>\n",
       "      <th>cat_1__ Winter Sports</th>\n",
       "      <th>cat_1__ Women's Accessories</th>\n",
       "      <th>cat_1__ Women's Clothing</th>\n",
       "      <th>cat_1__ Women's Shoes</th>\n",
       "      <th>cat_1__ Wood &amp; Timber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243809c0-9cfc-4486-ad12-3b7a16605ba9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>51.453489</td>\n",
       "      <td>-1.031873</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1c58d3f9-8b93-47ea-9415-204fcc2a22e6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>57.479012</td>\n",
       "      <td>-4.225739</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>860673f1-57f6-47ba-8d2f-13f9e05b8f9a</td>\n",
       "      <td>20.0</td>\n",
       "      <td>53.150228</td>\n",
       "      <td>0.329093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59948726-29be-4b35-ade5-bb2fd7331856</td>\n",
       "      <td>115.0</td>\n",
       "      <td>51.291949</td>\n",
       "      <td>-2.447623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16dbc860-696e-4cda-93f6-4dd4926573fb</td>\n",
       "      <td>450.0</td>\n",
       "      <td>53.568355</td>\n",
       "      <td>-2.026164</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7049</th>\n",
       "      <td>06d8a5c3-4f22-4d1b-ae7e-6ded471eb775</td>\n",
       "      <td>550.0</td>\n",
       "      <td>53.453547</td>\n",
       "      <td>-2.734323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7050</th>\n",
       "      <td>cce6d412-bac0-489e-9fba-cfdeeb756117</td>\n",
       "      <td>69.0</td>\n",
       "      <td>53.450693</td>\n",
       "      <td>-2.994883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7051</th>\n",
       "      <td>88d2d66b-2685-46b8-af84-f495fd2ccb14</td>\n",
       "      <td>380.0</td>\n",
       "      <td>53.450693</td>\n",
       "      <td>-2.994883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7052</th>\n",
       "      <td>8ca91ce8-49e7-4746-b06c-ac838d94ef35</td>\n",
       "      <td>650.0</td>\n",
       "      <td>53.485152</td>\n",
       "      <td>-2.898906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7053</th>\n",
       "      <td>df8ef910-03cc-4c9e-97a9-7f0a7e838102</td>\n",
       "      <td>10.0</td>\n",
       "      <td>51.272337</td>\n",
       "      <td>-0.721647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6628 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id  price_gbp       long       lat  \\\n",
       "0     243809c0-9cfc-4486-ad12-3b7a16605ba9        5.0  51.453489 -1.031873   \n",
       "1     1c58d3f9-8b93-47ea-9415-204fcc2a22e6       20.0  57.479012 -4.225739   \n",
       "2     860673f1-57f6-47ba-8d2f-13f9e05b8f9a       20.0  53.150228  0.329093   \n",
       "3     59948726-29be-4b35-ade5-bb2fd7331856      115.0  51.291949 -2.447623   \n",
       "4     16dbc860-696e-4cda-93f6-4dd4926573fb      450.0  53.568355 -2.026164   \n",
       "...                                    ...        ...        ...       ...   \n",
       "7049  06d8a5c3-4f22-4d1b-ae7e-6ded471eb775      550.0  53.453547 -2.734323   \n",
       "7050  cce6d412-bac0-489e-9fba-cfdeeb756117       69.0  53.450693 -2.994883   \n",
       "7051  88d2d66b-2685-46b8-af84-f495fd2ccb14      380.0  53.450693 -2.994883   \n",
       "7052  8ca91ce8-49e7-4746-b06c-ac838d94ef35      650.0  53.485152 -2.898906   \n",
       "7053  df8ef910-03cc-4c9e-97a9-7f0a7e838102       10.0  51.272337 -0.721647   \n",
       "\n",
       "      cat_0__Baby & Kids Stuff   cat_0__Clothes, Footwear & Accessories   \\\n",
       "0                             0                                        0   \n",
       "1                             0                                        0   \n",
       "2                             0                                        0   \n",
       "3                             0                                        0   \n",
       "4                             0                                        0   \n",
       "...                         ...                                      ...   \n",
       "7049                          0                                        0   \n",
       "7050                          0                                        0   \n",
       "7051                          0                                        0   \n",
       "7052                          0                                        0   \n",
       "7053                          0                                        0   \n",
       "\n",
       "      cat_0__Computers & Software   cat_0__DIY Tools & Materials   \\\n",
       "0                                0                              0   \n",
       "1                                0                              0   \n",
       "2                                0                              0   \n",
       "3                                0                              0   \n",
       "4                                0                              0   \n",
       "...                            ...                            ...   \n",
       "7049                             0                              0   \n",
       "7050                             0                              0   \n",
       "7051                             0                              0   \n",
       "7052                             0                              0   \n",
       "7053                             0                              0   \n",
       "\n",
       "      cat_0__Health & Beauty   cat_0__Home & Garden   ...  \\\n",
       "0                           0                      1  ...   \n",
       "1                           0                      1  ...   \n",
       "2                           0                      1  ...   \n",
       "3                           0                      1  ...   \n",
       "4                           0                      1  ...   \n",
       "...                       ...                    ...  ...   \n",
       "7049                        0                      0  ...   \n",
       "7050                        0                      0  ...   \n",
       "7051                        0                      0  ...   \n",
       "7052                        0                      0  ...   \n",
       "7053                        0                      0  ...   \n",
       "\n",
       "      cat_1__ Washer Dryers  cat_1__ Washing Machines  cat_1__ Watches  \\\n",
       "0                         0                         0                0   \n",
       "1                         0                         0                0   \n",
       "2                         0                         0                0   \n",
       "3                         0                         0                0   \n",
       "4                         0                         0                0   \n",
       "...                     ...                       ...              ...   \n",
       "7049                      0                         0                0   \n",
       "7050                      0                         0                0   \n",
       "7051                      0                         0                0   \n",
       "7052                      0                         0                0   \n",
       "7053                      0                         0                0   \n",
       "\n",
       "      cat_1__ Water Sports   cat_1__ Wedding Clothes & Accessories   \\\n",
       "0                         0                                       0   \n",
       "1                         0                                       0   \n",
       "2                         0                                       0   \n",
       "3                         0                                       0   \n",
       "4                         0                                       0   \n",
       "...                     ...                                     ...   \n",
       "7049                      0                                       0   \n",
       "7050                      0                                       0   \n",
       "7051                      0                                       0   \n",
       "7052                      0                                       0   \n",
       "7053                      0                                       0   \n",
       "\n",
       "      cat_1__ Winter Sports   cat_1__ Women's Accessories   \\\n",
       "0                          0                             0   \n",
       "1                          0                             0   \n",
       "2                          0                             0   \n",
       "3                          0                             0   \n",
       "4                          0                             0   \n",
       "...                      ...                           ...   \n",
       "7049                       0                             0   \n",
       "7050                       0                             0   \n",
       "7051                       0                             0   \n",
       "7052                       0                             0   \n",
       "7053                       0                             0   \n",
       "\n",
       "      cat_1__ Women's Clothing   cat_1__ Women's Shoes   cat_1__ Wood & Timber  \n",
       "0                             0                       0                      0  \n",
       "1                             0                       0                      0  \n",
       "2                             0                       0                      0  \n",
       "3                             0                       0                      0  \n",
       "4                             0                       0                      0  \n",
       "...                         ...                     ...                    ...  \n",
       "7049                          0                       0                      0  \n",
       "7050                          0                       0                      0  \n",
       "7051                          0                       0                      0  \n",
       "7052                          0                       0                      0  \n",
       "7053                          0                       0                      0  \n",
       "\n",
       "[6628 rows x 130 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from clean_tabular import TabularCleanse\n",
    "cleanse = TabularCleanse('fb_marketplace_conn.json', 'aicore2022!')\n",
    "products = cleanse.remove_rows_conditonal(products, 'price_gbp', 1000.00, '<')\n",
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        id       long       lat\n",
      "0     243809c0-9cfc-4486-ad12-3b7a16605ba9  51.453489 -1.031873\n",
      "1     1c58d3f9-8b93-47ea-9415-204fcc2a22e6  57.479012 -4.225739\n",
      "2     860673f1-57f6-47ba-8d2f-13f9e05b8f9a  53.150228  0.329093\n",
      "3     59948726-29be-4b35-ade5-bb2fd7331856  51.291949 -2.447623\n",
      "4     16dbc860-696e-4cda-93f6-4dd4926573fb  53.568355 -2.026164\n",
      "...                                    ...        ...       ...\n",
      "7049  06d8a5c3-4f22-4d1b-ae7e-6ded471eb775  53.453547 -2.734323\n",
      "7050  cce6d412-bac0-489e-9fba-cfdeeb756117  53.450693 -2.994883\n",
      "7051  88d2d66b-2685-46b8-af84-f495fd2ccb14  53.450693 -2.994883\n",
      "7052  8ca91ce8-49e7-4746-b06c-ac838d94ef35  53.485152 -2.898906\n",
      "7053  df8ef910-03cc-4c9e-97a9-7f0a7e838102  51.272337 -0.721647\n",
      "\n",
      "[6898 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEcCAYAAADtODJSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAxt0lEQVR4nO3de1hUBcIG8Hcu3EHul+GieEvdNZVAUFfTUBINMy2LspuZu6am1rqrn9kNS7O2DLtotuSz1a6Zppmmq5amW5ZZqZhlKgOonOF+GRhgYGbO9wcySqAyDDNnhnl/z+PjzLm+gJ6Xc86cc2SiKIogIiLqILnUAYiIyLmxSIiIyCosEiIisgqLhIiIrMIiISIiq7BIiIjIKiwSojZs3boV9957r/l9v379kJ+fL2EiIsellDoAkVSSk5NRWloKhUJhHjZlyhQ888wzEqa6rLi4GK+//joOHToEnU6H8PBwTJw4EY8++ii8vb2ljkdkxiIhl7Zu3TqMGDFC6hitVFZWIj09HXFxcfjoo48QHR0NjUaDrKwsnD9/Hv3797doeQaDAUol/7uTbfDQFlE7HTx4EGPHjkVSUhJWrVoFk8kEADCZTHj77bdxyy23YPjw4fj73/+O6upqAMDixYvx3nvvAQCKiorQr18//Pvf/wYA5OfnIzExEW3dXGLDhg3w8fHBK6+8gujoaACASqXCsmXL0L9/f1y8eBH9+vWDwWAwz/PAAw9g8+bNAJoOzaWnp2PFihVITExEZmYmEhIScObMGfP05eXlGDRoEMrKygAABw4cwOTJk5GQkID09HScPn26s7+F1EWxSIjaad++ffjkk0+wbds27N+/H5988gmApo32tm3b8P777+OLL75AbW0tMjIyAABDhw7F999/DwD4/vvvERMTg6NHjwIAjh49ivj4eMhkslbr+vbbb5GSkgK5vOP/RbOzsxETE4PDhw9j7ty5SElJweeff24ev3v3bgwdOhTBwcE4deoUli5dioyMDBw5cgT33HMP5syZg4aGhg6vn1yHyxbJqlWrkJycjH79+rX4Le1aKisr8eSTT2L8+PG47bbb8Oabb9o4Jdna3LlzkZCQYP7z8ccfX3XaWbNmISAgAJGRkXjwwQexc+dOAMCOHTvw8MMPIyYmBj4+PnjyySexa9cuGAwGJCYm4ocffoDJZMLRo0fx6KOP4qeffgLQVCSJiYltrquyshKhoaFWfW1hYWF44IEHoFQq4enpiUmTJpkzN+eeNGkSAODjjz/GPffcg8GDB0OhUGDKlClwc3PD8ePHrcpArsFlD5qOHTsWDz74IKZPn97ueZYsWYJhw4bhtddeAwCUlpbaKh7ZyVtvvdXucyQqlcr8OioqCsXFxQCaTopHRUW1GGcwGFBWVobu3bvD29sbv/76K3788UfMnTsXW7ZsgVqtxtGjR/HAAw+0ua6AgACUlJRY8ZUBERERLd4PGzYMer0eJ06cQEhICE6fPo1x48YBAARBwKeffooPP/zQPH1jY6P5ayS6FpctkoSEhDaHnzhxAv/4xz+g0+kAAPPnz8eYMWOQl5eHM2fOYO3ateZpQ0JC7JKVHINGo0Hfvn0BNG14w8LCADT95l9QUGCeThAEKJVKBAcHA2g6vLVnzx40NjYiPDwcQ4cOxfbt21FVVYUBAwa0ua7hw4dj3759mDdvXpuHt5o/tVVfXw9fX18AaFU8vz9kJpfLkZqaip07dyIkJARjxowxz6tSqTB79mw89thjFn9fiFz20FZbtFotnn32Wbz66qvYunUr1q1bh2eeeQZarRbnzp1DeHg4nnrqKUyZMgWzZs3C2bNnpY5MdpSVlYWqqipoNBq8//77mDhxIgAgLS0N//rXv3DhwgXodDqsXr0aEyZMMH9KKjExER9++KH5l5ekpCR88MEHiI+Pb/HR4yvNmDEDOp0OixcvNpdUUVERVq5cidOnTyMoKAjh4eHYvn07jEYjtmzZggsXLlz3a5g0aRJ2796NHTt2IC0tzTx82rRp+Oijj3DixAmIooja2lp89dVXqKmpsep7Rq7BZfdI2nLs2DFcvHgRs2bNMg+TyWTIz8+H0WjEiRMn8Ne//hUJCQnYu3cvHnvsMXzxxRcSJiZrzZ49u8XGfMSIEXjrrbfanHbs2LGYOnUqampqMGXKFNx1110AgDvvvBNFRUW4//77odfrMXLkSDz99NPm+YYOHQqdToehQ4cCAOLj41FfX3/VvWKg6dDWxo0b8frrr+Puu+9GbW0twsPDkZaWhh49egAAli9fjueffx6rV6/GXXfdhbi4uOt+vYMHD4aXlxeKi4tx8803m4ffeOONWL58OTIyMpCfnw9PT0/cdNNN18xI1Ezm6g+2Sk5Oxrp163DDDTfgq6++wrvvvmv+eOaVTp48iYULF+LLL780Dxs8eDAOHDiAoKAge0YmInIoPLR1hbi4OOTn5+O7774zD8vOzoYoihg4cCC8vb3Nh7OOHj0Kf39/BAYGShWXiMghuOweyQsvvIC9e/eitLQUgYGBCAgIwOeff47s7Gy88sorqKqqQmNjI2JiYrBu3TrI5XKcPHkSzz//PBoaGuDl5YWnnnoKgwYNkvpLISKSlMsWCRERdQ4e2iIiIquwSIiIyCosEiIisopLXkdSUaGDydSxU0PBwb4oK3O8i7SYyzLMZRnmskxXyyWXyxAY6HPV8S5ZJCaT2OEiaZ7fETGXZZjLMsxlGVfKxUNbRERkFRYJERFZhUVCRERWcagiyc3NxT333IPx48fjnnvuQV5eXqtpjEYjnn/+eYwbNw4pKSnmR4sSEZE0HKpInn32Wdx3333Ys2cP7rvvPjzzzDOtptmxYwfOnz+PvXv3YtOmTXjjjTdw8eJFCdISERHgQEVSVlaGX375xfyMhLS0NPzyyy8oLy9vMd2uXbswbdo0yOVyBAUFYdy4cfjvf/8rRWQiIqcgiiJMNrwblsN8/Fej0SA8PNz8bAiFQoGwsDBoNJoWt2nXaDSIjIw0v1epVCgsLLRoXcHBvlZlDQ31s2p+W2EuyzCXZdrKJYoijKZLf4wmGIwijCYTjEYRBqPJPNxouvTeKP7u9eV5DEYRpub35mVdem26PO+V6zGZRIgARLEpS/PfpiteiwBE0+XXTePE380D84bWJIoQzcttY7xJvLxcUYTpUoCmv69Y/u9yAZeXJeJ3+a5cRpvTXZ621XTAFXlbTmde9iUzbx+IO0b37tx/GHCgIrGnsrKaDn+WOjTUDyUl1Z2cyHrMZZmumEsURRiMIhoMRjQ0mqBvNKKh8dJrQ9Nr/aX3DY1GNBhMrYbpLw1rGm66tCwjRBFoMJjMpWAyXS4Qe5LJAIVcDoVCBoVMBoVCDkCETCaD7NJ4mUzW9Dcu/d08DFeMM0/T1vRXme+K5cvN08kuz3fFsjw93dCgN0B2aaYW2QDgyvU1v29zuiuGNc3UIisAyC8t5Mr1A21PF98/rEP/vuRy2TV/AXeYIlGpVCgqKoLRaIRCoYDRaERxcTFUKlWr6QRBMN++/fd7KESOThRF6BuNqK03oE5vQJ3eiFp9I2r1Brh7lKOsQne5AK7Y4Ddv/PUNxpZlYbhcGh05euHuJoe7UgEPNznc3RRwd1PAQymHj6cSgW4ecFfK4evjgcZGAxRyWdOGXC5r2pjLm/7Im4crZFD+7n3zNM3v5fKmaczvZVcsSyG/VBBtzyf/3XPou+IvBLZkq1wOUyTBwcEYMGAAdu7cicmTJ2Pnzp0YMGBAq6cPpqamYvPmzbj11ltRWVmJL774os0nGhLZSqPBiFq9EXV6wxVlYEDtFe9r9VcMbzXM2K7j1TLg0oa9aUPv7iaHx6UNvY+XG4L8Wg67PN0VpXBFQXj8bllN4+WQ/W7j3BZH3TCSY3CYIgGA5557DkuWLMHbb7+Nbt26YdWqVQCAWbNmYf78+bjxxhsxefJknDhxArfeeisAYO7cuYiJiZEyNjmZOr0BhWU6XCysbrGBr9UbUFf/u/etysAIg9F0zeXLAHh6KOHtoYCXhxu8PRQI9PNAVKgPvDyU8PJQwtvz0t+X/jQPj4zwR011HdyVcri1cyNPJDWXfLAVz5HYj1S5ausbUVRRh6KKWhSX16Goog7FFbUoqqhDTV3jNef1cFPAy0NxzQ1+8/Dfj/P2VMLDXdHqEEx78edoGeayTEdzOc05EiJLWVIWQd08EB7ojfh+oQgL9EJUeDcYGgzmIvDybPrb010BpcJhPhVP5BRYJOTQWpdFLYor6q5bFuGB3ggP9EJYoBdCA7zg7qZoMa2j/sZI5IxYJCQ5W5UFEdkHi4TswlwW5c0lwbIg6ipYJNTp6vQG/JxbjpM5ZSjR1qOguIZlQdSFsUioU1RU63H8XCmOnS3B6fwKGIwifDyV6B0dwLIg6uJYJNQhoiiioFSHY2dLcfxsCXI1TSeuwwK9MDY+GnF9Q9Enyh/h4d14Upuoi2ORULsZTSacu1iFY2eb9jxKKusBAL0iu+HO0b0wpG8oIoO9eREdkYthkdA11TcYcCq3HMfOluLEuVLo6g1QKuT4Q2wgJgzrgSF9QhDg6yF1TCKSEIuEWqmsaTrfcfxsKX7Jq4DBaIKPpxKDeocgrm8IBvYKgqc7/+kQURNuDQiiKEIoq8XxsyU4drYUakELAAgN8ETyTVEY0icEfWP8oZDzim8iao1F4qJMJhHnCqpw7FJ5FFfUAQB6qvww5eZeiOsbgqgQH57vIKLrYpG4EH2DEafyynHsbAlOnCtDTV0jlAoZ+vcIxPjE7hjSJwSBfjzfQUSWYZF0cVW6Bpy4dL7jVF45Gg0meHsoMahPMOL6hmJgzyB4efCfARF1HLcgXZCmTIfjZ0tx7GwpcgqqIAII7uaJ0YMjEdc3BH1jAniHWyLqNCySLsBkEvFLbhkOHD2PY2dLUVReCwDoEe6HySN7YkjfEMSE+fJ8BxHZBIvEydXUNeKFf/2A4so6KOQy9O8egHHx0YjrG4Kgbp5SxyMiF8AicXKn8ytQXFmHWZMHYnDPIHh78kdKRPbFA+VOTi1ooVTIMGFELEuEiCTBInFyaqEK3cP94Kbk3XSJSBosEidmMJqQV1iNXpHdpI5CRC6MReLECkp0aDCYWCREJCkWiRNTC1UAgN6R/hInISJXxiJxYmpBCz9vN4T482O+RCQdFokTyxG06B3pzwsNiUhSLBInpatvRGF5LXry/AgRSYxF4qRyLz0zpDeLhIgkxiJxUmpBCxmAnioWCRFJi0XipNQaLSJDfHgLeCKSnEMUSV1dHRYuXIiUlBSkpqbiwIEDbU73xRdfYOrUqUhLS8Ntt92G9957z85JHYMoilALWp4fISKH4BC/zmZlZcHHxwf79u1DXl4epk+fjr1798LHx6fFdKGhoVi7di3Cw8NRXV2NqVOnYtCgQUhISJAouTSKK+tQU9fI8yNE5BAcYo9k9+7dSE9PBwDExsZi4MCBOHToUKvpBg8ejPDwcACAn58fevfujYKCArtmdQTqgqYT7b14ISIROQCHKBJBEBAVFWV+r1KpUFhYeM15cnJycPz4cQwbNszW8RyOWtDCw02BqBCf609MRGRjdjm0NWXKFAiC0Oa4w4cPW7y84uJizJkzB88884x5D8USwcG+Fs9zpdBQP6vmt1Z+SQ1u6B6I8PCWh7akznU1zGUZ5rIMc1nGFrnsUiTbtm275vjIyEgUFBQgKCgIAKDRaJCUlNTmtGVlZZgxYwYeffRRTJw4sUN5yspqYDKJHZo3NNQPJSXVHZq3MzQ0GpFbUIVbE2Na5JA619Uwl2WYyzLMZZmO5pLLZdf8BdwhDm2lpqZi06ZNAIC8vDycPHkSo0aNajVdRUUFZsyYgenTp2PatGn2jukQzhfVwGgSeaNGInIYDlEkM2fOhFarRUpKCv7yl78gIyMDvr5N7ZeZmYmNGzcCANavX4+8vDxs2rQJkydPxuTJk/HJJ59IGd3umu/4y1vHE5GjcIiP/3p7e2PNmjVtjluwYIH59eLFi7F48WJ7xXJIOYIWwd08EODrIXUUIiIADrJHQu3XdCEiD2sRkeNgkTiRqho9yrT1vBCRiBwKi8SJqIXmCxFZJETkOFgkTiRH0EIhl6FHuGN+Pp2IXBOLxImohSpEh/nC3U0hdRQiIjMWiZMwmUTkFlbz/AgRORwWiZMQSnXQNxh5foSIHA6LxEnkXLoQkVe0E5GjYZE4CbWghY+nEmGBXlJHISJqgUXiJNQaLXpF+kMmk0kdhYioBRaJE6jTGyCU6Hh+hIgcEovECeRptBDBCxGJyDGxSJxAzqUr2nuqWCRE5HhYJE5ALWgRHuQNXy83qaMQEbXCInFwoihCLVTxQkQiclgsEgdXVlUPbW0jz48QkcNikTi45vMjvBCRiBwVi8TBqQUt3JRyRIX6SB2FiKhNLBIHpxaqEBvhB6WCPyoickzcOjmwRoMJ+UU1PD9CRA6NReLALhTXwGA08fwIETk0FokDU1+64y/3SIjIkbFIHJha0CLA1x2Bfh5SRyEiuioWiQNTC7zjLxE5PhaJg9LWNqC4so5XtBORw2OROKjcSxci8vwIETk6FomDyhG0kMmA2AgWCRE5NhaJg8oVqhAd6gsPd4XUUYiIrolF4oBMogi1pprnR4jIKbBIHFBhWS3q9Ab0ZJEQkRNwiCKpq6vDwoULkZKSgtTUVBw4cOCa0+v1ekycOBFTp061U0L7UptPtPOKdiJyfA5RJFlZWfDx8cG+ffuwbt06LFu2DDqd7qrTr169GkOGDLFfQDtTC1Xw8lBAFewtdRQioutyiCLZvXs30tPTAQCxsbEYOHAgDh061Oa0P/zwA/Ly8jB58mR7RrQrtaBFT1U3yHkhIhE5AaXUAQBAEARERUWZ36tUKhQWFraarra2FitWrMDatWuRl5fX4fUFB/t2eF4ACA31s2r+a6nXG3CxpAbTxt5g8XpsmcsazGUZ5rIMc1nGFrnsUiRTpkyBIAhtjjt8+HC7l/Pyyy/jvvvuQ3h4uFVFUlZWA5NJ7NC8oaF+KCmp7vC6r+e38xUwiUB4gKdF67F1ro5iLsswl2WYyzIdzSWXy675C7hdimTbtm3XHB8ZGYmCggIEBQUBADQaDZKSklpN9+OPP+LQoUN4++23odfrUVVVhUmTJmHHjh02yS0FNa9oJyIn4xCHtlJTU7Fp0ybceOONyMvLw8mTJ/Hqq6+2mu7Kwjhy5AhWrVqFrVu32jOqzakFLUIDPNHN213qKERE7eIQJ9tnzpwJrVaLlJQU/OUvf0FGRgZ8fZt2ozIzM7Fx40aJE9pPjlDFB1kRkVNxiD0Sb29vrFmzps1xCxYsaHN4UlJSl9sbKdfWo7KmgRciEpFTcYg9EmrSfH6EeyRE5ExYJA5ELWihVMgQE2bdx5OJiOyJReJAcoQq9Aj3g5uSPxYich4WbbG++eYbLF26FLNnzwYAnDx5Et9++61Ngrkag9GE/MJqnh8hIqfT7iL54IMP8NxzzyE2NhZHjx4FAHh6eiIzM9Nm4VxJQYkODQYTz48QkdNpd5H861//woYNG/DnP/8ZcnnTbL169UJubq7NwrkStVAFgBciEpHzaXeR6HQ6qFQqAIDs0s0EDQYD3NzcbJPMxeQIWnTzdkOIv6fUUYiILNLuIhk6dCjWr1/fYtj777/f5q1MyHJqQYtekf7mkiYichbtviBx2bJlmD17NjZv3gydTofx48fD19cX69ats2U+l6Crb0RheS1GDIyQOgoRkcXaVSQmkwk5OTn4z3/+gzNnzqCgoAAqlQqDBg0yny+hjsvljRqJyIm1q0jkcjnmzJmDY8eOYdCgQRg0aJCtc7kUtaCFDEBPFYuEiJyPRedIjh8/bsMoritH0CIyxAdeHg5x6zMiIou0e8sVGRmJWbNmYezYsYiIiGhxUvhqN1ak6xNFEWqhCnE3hEodhYioQ9pdJHq9HuPGjQMAFBUV2SyQqymuqIOu3oDePD9CRE6q3UWycuVKW+ZwWZefiMgr2onIOVl0UD4vLw87d+5EcXExwsLCkJaWhtjYWBtFcw05QhU83BSICvGROgoRUYe0+2T7/v37MXXqVOTm5sLf3x+5ubm488478eWXX9oyX5enFrToqfKDXM4LEYnIObV7j2T16tV4++23MWzYMPOwI0eOYPny5Rg7dqxNwnV1DY1GXCiuwfjE7lJHISLqsHbvkRQWFiIhIaHFsPj4eBQWFnZ6KFdxvqgGRpPICxGJyKm1u0j69++P9957r8WwDRs2YMCAAZ0eylXk8I6/RNQFtPvQ1nPPPYfHHnsM77//PlQqFTQaDby9vbF27Vpb5uvS1IIWwd08EODrIXUUIqIOa3eR9O7dG7t27cLx48fNn9oaPHgwbyNvBbVQxY/9EpHTa3eR/PrrrwgICGhxnkSj0aCqqgr9+/e3SbiurLJGjzKtHuMSeFiLiJxbu8+R/O1vf4PBYGgxrLGxEX/72986PZQraL4QkY/WJSJn1+4iEQQBMTExLYZ1794dBQUFnR7KFagFLRRyGbqH+0odhYjIKu0ukoiICJw6darFsFOnTiEsLKzTQ7kCtVCFmDBfuLsppI5CRGSVdp8jefjhhzFnzhw8+uij6N69O/Lz87FhwwbMnj3blvm6JJNJRG5hNf7EJyISURfQ7iK5++674efnhy1btqCoqAgRERFYsmQJxo8fb8t8XZJQqoO+wcjrR4ioS7juoa2ff/4ZZ86cAQBMmDABL7/8Mvr164eioiJ888030Ol0Ng/Z1TRfiMgT7UTUFVy3SFasWIHS0lLz+6effhr5+flIT0/H2bNn8corr1gdoq6uDgsXLkRKSgpSU1Nx4MCBq07766+/Yvr06Zg4cSImTpyIgwcPWr1+e1MLWvh4KhEW6CV1FCIiq1330FZOTo752hGtVouDBw9i586d6NmzJ5KTk5Geno7nnnvOqhBZWVnw8fHBvn37kJeXh+nTp2Pv3r3w8Wl5a/Xa2lrMmzcPr776KoYMGQKDwYDq6mqr1i0FtaBFr0j/Fk+ZJCJyVtfdIzEajear148fP47Q0FD07NkTAKBSqaDVaq0OsXv3bqSnpwMAYmNjMXDgQBw6dKjVdDt37kR8fDyGDBkCAFAqlQgMDLR6/fZUpzdAKNXx/AgRdRnXLZI+ffpg9+7dAIBdu3Zh+PDh5nFFRUXw8/OzOoQgCIiKijK/V6lUbd5V+Ny5c1AqlZg1axYmT56MpUuXoqqqyur121OuRgsR4KN1iajLuO6hrUWLFuGxxx7Dc889B7lcjv/85z/mcbt27cJNN9103ZVMmTIFgiC0Oe7w4cPtDms0GvHdd9/ho48+QkhICFauXImXXnrJ4scABwdbdxFgaGjHy7PohAYAMPTGSPh6u1uV4/esyWVLzGUZ5rIMc1nGFrmuWyQJCQk4cOAA8vLyEBsbC1/fyxvh0aNHY+LEidddybZt2645PjIyEgUFBQgKCgLQdA+vpKSkNqdLSkoyXwQ5adIkLF269Lrr/72yshqYTKLF8wFNP4SSko6flzl5tgQRQd6o0+lRp9N3eDmdnctWmMsyzGUZ5rJMR3PJ5bJr/gLerivbfX19MXDgwBYlAgC9evVCeHi4xaF+LzU1FZs2bQLQ9Fz4kydPYtSoUa2mmzBhAk6ePImamhoAwKFDh9CvXz+r128voiheuuMvD2sRUdfR7gsSbWnmzJlYsmQJUlJSIJfLkZGRYS6tzMxMhIWF4d5770VkZCQeffRRpKenQyaTITo6GsuXL5c4ffuVVtVDW9vI8yNE1KU4RJF4e3tjzZo1bY5bsGBBi/d33HEH7rjjDjuk6nzNd/zlM0iIqCtp900byXo5QhXclXJEhfpcf2IiIifBIrGjXEGLHhF+UCr4bSeiroNbNDtpNJiQX1TN+2sRUZfDIrGTC8U1MBhFfmKLiLocFomdNN/xl0VCRF0Ni8ROcgUtAnzdEdTNU+ooRESdikViJzlCFc+PEFGXxCKxA21tA0oq63lYi4i6JBaJHVy+EJFFQkRdD4vEDtSCFjIZEBvBIiGirodFYge5QhWiQ33h4a6QOgoRUadjkdiYSRSh1mh5o0Yi6rJYJDZWWFaLOr0RPVkkRNRFsUhsrPlCRH70l4i6KhaJjeUKWnh5KBER7C11FCIim2CR2FiOoEUvlR/kMpnUUYiIbIJFYkP6BiMultSgJw9rEVEXxiKxobxCLUQR/MQWEXVpLBIbar6inZ/YIqKujEViQzmCFmEBXujm7S51FCIim2GR2IgoisgRqnh/LSLq8lgkNlJRrUdVTQOLhIi6PBaJjVy+4y8/sUVEXRuLxEZyhCooFXJ0D/eVOgoRkU2xSGxELWjRI9wXSgW/xUTUtXErZwMGowl5hdU8rEVELoFFYgMFJTo0Gkw80U5ELoFFYgPNd/xlkRCRK2CR2IBa0KKbtxtC/D2ljkJEZHMsEhtQC1r0ivSHjHf8JSIX4BBFUldXh4ULFyIlJQWpqak4cOBAm9OZTCa88MILuO222zBp0iTMnDkTRUVFdk57bbr6RhSW1/KwFhG5DIcokqysLPj4+GDfvn1Yt24dli1bBp1O12q6/fv3Izs7G9u3b8eOHTvQp08frF27VoLEV5drvhCRRUJErsEhimT37t1IT08HAMTGxmLgwIE4dOhQm9M2NDRAr9fDZDJBp9MhIiLCnlGvK0fQQgagp4pFQkSuQSl1AAAQBAFRUVHm9yqVCoWFha2mS05Oxvfff4+RI0fC09MTvXr1wjPPPGPPqNelFrSIDPGBl4dDfGuJiGzOLlu7KVOmQBCENscdPny43cs5deoUcnJycOjQIXh7e2PFihV46aWXLC6T4GDrblsSGurX5nBRFJFXqMWwgaqrTmNLUqyzPZjLMsxlGeayjC1y2aVItm3bds3xkZGRKCgoQFBQEABAo9EgKSmpzeUMGzYMfn5N34jbb78dS5cutThPWVkNTCbR4vmAph9CSUl1m+OKymtRXduIyCCvq05jK9fKJSXmsgxzWYa5LNPRXHK57Jq/gDvEOZLU1FRs2rQJAJCXl4eTJ09i1KhRraaLjo7Gd999h8bGRgDAwYMH0bdvX7tmvZbmCxF789YoRORCHOJA/syZM7FkyRKkpKRALpcjIyMDvr5N7ZeZmYmwsDDce++9mD59Os6ePYvbb78dSqUSKpUKy5cvlzj9ZWpBCw93BSJDfKSOQkRkNw5RJN7e3lizZk2b4xYsWGB+7eHhgZUrV9orlsVyBC16RvhBLueFiETkOhzi0FZX0NBoxMXiGt7xl4hcDoukk+QXVcNoEtGbFyISkYthkXQSNa9oJyIXxSLpJDmCFsHdPOHv6yF1FCIiu2KRdJJcoYp7I0TkklgknaCyRo8yrZ7nR4jIJbFIOsHl8yP8xBYRuR4WSSfIEaqgkMvQPdy6e3gRETkjFkknyBW0iAnzhbubQuooRER2xyKxkskkIldTzRPtROSyWCRWKijVQd9o5I0aichlsUispL50x1/ukRCRq2KRWClH0MLHU4mwQC+poxARSYJFYqVcQYtekf6QyXjHXyJyTSwSK9TpDRBKdbwQkYhcGovECrkaLUTw/AgRuTYWiRVyLl3R3pNFQkQujEVihVxBi4ggb/h4ukkdhYhIMiySDhJFETlCFc+PEJHLY5F0UGlVPaprG3l+hIhcHoukg3LMFyLyinYicm0skg5SC1q4K+WIDvOROgoRkaRYJB2kFrSIjfCDQs5vIRG5Nm4FO6DRYML5omoe1iIiAoukQ84XV8NgFHminYgILJIOufxoXRYJERGLpAPUghYBvu4I6uYpdRQiIsmxSDpALVTxQVZERJewSCxUVaNHSWU9D2sREV3iEEWyfft2TJo0CX/4wx/w4YcfXnPajz/+GCkpKRg3bhwyMjJgMpnslLLJb+crAPD8CBFRM4cokgEDBmD16tVIS0u75nQXLlzAm2++iU2bNmHv3r3Iz8/HZ599ZqeUTc7kV0AukyE2gkVCRAQ4SJHccMMN6NOnD+TXubhvz549GDduHIKCgiCXyzFt2jTs2rXLTimb/JZfgehQH3i4K+y6XiIiR+UQRdJeGo0GkZGR5veRkZHQaDR2W79JFHHmQgUPaxERXUFpj5VMmTIFgiC0Oe7w4cNQKOz7231wsG+H5jtfqEVtvQGD+4UjNNSvk1NZzxEzAcxlKeayDHNZxha57FIk27Zt65TlqFSqFoUkCAJUKpXFyykrq4HJJFo83w+nmvZ+Qv3cUVJSbfH8thQa6udwmQDmshRzWYa5LNPRXHK57Jq/gDvVoa3x48fjiy++QHl5OUwmEzZv3owJEybYbf1qQQsfTyUigr3ttk4iIkfnEEWyc+dO3Hzzzfjvf/+LzMxM3HzzzTh37hwAIDMzExs3bgQAxMTEYM6cObj77rtx6623Ijo6GrfffrvdcqoFLfp2D4RcJrPbOomIHJ1dDm1dT1pa2lU/+rtgwYIW79PT05Genm6PWC3UNxhwsaQGIwZHXn9iIiIX4hB7JM6gTm8EAMTdECZxEiIix8IiaadAPw+89cTN+GOvYKmjEBE5FBaJBTzdHeJIIBGRQ2GREBGRVVgkRERkFRYJERFZhUVCRERWYZEQEZFVWCRERGQVl/w8q1xu3S1OrJ3fVpjLMsxlGeayTFfKdb15ZKIoWn4bXCIiokt4aIuIiKzCIiEiIquwSIiIyCosEiIisgqLhIiIrMIiISIiq7BIiIjIKiwSIiKyCouEiIis4pK3SLHUqlWrsGfPHhQUFGDHjh244YYbpI4EAKioqMDf//53nD9/Hu7u7ujRowcyMjIQFBQkdTTMmTMHFy9ehFwuh7e3N55++mkMGDBA6lhmb775Jt544w2H+XkmJyfD3d0dHh4eAIBFixZh1KhREqcC9Ho9VqxYgW+//RYeHh4YMmQIli9fLmmmixcvYu7cueb31dXVqKmpwffffy9hqiYHDhxAZmYmRFGEyWTC448/jltvvVXqWPjqq6+QmZkJg8EAf39/rFy5EjExMZ23ApGu6+jRo6IgCOItt9wi/vbbb1LHMauoqBC/++478/uXXnpJ/L//+z8JE12m1WrNr/ft2yfecccdEqZp6eeffxZnzpwpjhkzxmF+no72b6vZ8uXLxRdffFE0mUyiKIpiSUmJxIlae+GFF8Tnn39e6hiiyWQSExISzD/HX3/9VRwyZIhoNBolzVVZWSkmJiaKarVaFEVR/PTTT8VHHnmkU9fBQ1vtkJCQAJVKJXWMVgICApCUlGR+P2TIEAiCIGGiy/z8/Myva2pqIJM5xg3sGhoakJGRgWeffdZhMjkqnU6HTz/9FAsWLDB/r0JCQiRO1VJDQwN27NiBO++8U+ooAAC5XI7q6moATXtKYWFhkMul3czm5+cjJCQEPXv2BACMHj0aX3/9NcrLyzttHTy01UWYTCZs3LgRycnJUkcxe+qpp/DNN99AFEX885//lDoOACAzMxO333575+7Wd5JFixZBFEXEx8fjySefRLdu3STNc+HCBQQEBODNN9/EkSNH4OPjgwULFiAhIUHSXFfav38/wsPD8cc//lHqKJDJZHj99dcxZ84ceHt7Q6fT4Z133pE6Fnr27InS0lJkZ2dj0KBB2LFjBwBAo9F02mFw7pF0EcuXL4e3tzfuv/9+qaOYvfjii/jqq6/wxBNP4OWXX5Y6Do4dO4aTJ0/ivvvukzpKK//+97/x2Wef4ZNPPoEoisjIyJA6EgwGAy5cuIA//OEP2Lp1KxYtWoTHH38cNTU1Ukcz++STTxxmb8RgMOCdd97B22+/jQMHDmDt2rV44oknoNPpJM3l5+eH1atXY+XKlZg6dSrKysrQrVs3KJWdtx/BIukCVq1ahfz8fLz++uuS70a35Y477sCRI0dQUVEhaY6jR49CrVZj7NixSE5ORmFhIWbOnImvv/5a0lwAzIdO3d3dcd999+Gnn36SOBEQGRkJpVKJtLQ0AMDgwYMRGBiI3NxciZM1KSoqwtGjRzFp0iSpowAAfv31VxQXFyM+Ph4AEB8fDy8vL+Tk5EicDBgxYgQ2btyIrVu34v7770d9fX2n7pU73laHLLJ69Wr8/PPPeOutt+Du7i51HABNx9Y1Go35/f79++Hv74+AgADpQgH485//jK+//hr79+/H/v37ERERgaysLIwcOVLSXLW1tebj6qIoYteuXQ7xCbegoCAkJSXhm2++AQDk5uairKwMPXr0kDhZk23btmH06NEIDAyUOgoAICIiAoWFhVCr1QCAnJwclJaWonv37hInA0pKSgA0HQJ/7bXXkJ6eDm9v705bPh9s1Q4vvPAC9u7di9LSUgQGBiIgIACff/651LFw9uxZpKWlITY2Fp6engCA6OhovPXWW5LmKi0txZw5c1BXVwe5XA5/f38sXrzYIY5jXyk5ORnr1q2T/OO/Fy5cwOOPPw6j0QiTyYTevXtj2bJlCAsLkzRXc7alS5eisrISSqUSCxcuxOjRo6WOBQAYP348nnrqKdx8881SRzH77LPP8O6775o/nDB//nyMGzdO4lRN5yt/+uknNDY24k9/+hOWLl1q/qh5Z2CREBGRVXhoi4iIrMIiISIiq7BIiIjIKiwSIiKyCouEiIiswiIhasOSJUuwevVqSdYtiiL+7//+D0OHDsVdd93VoWX069cP+fn5nZyMqG0sEnIKycnJGDFiBGpra83DNm/ejAceeEDCVLbx448/4ptvvsHBgwexZcuWNqcpLi7G0qVLMXLkSMTFxSE1NRVr1qxp8f2xlpRlSs6FRUJOw2g04v3335c6hsWMRqNF0xcUFCAqKuqqVx5XVlYiPT0der0eH330EY4dO4YNGzZAq9Xi/PnznRG5UxgMBqkjkJ2wSMhpzJw5E++99x60Wm2rcRcvXkS/fv1abLweeOABbN68GQCwdetWpKenY8WKFUhISMDYsWPx008/YevWrRg9ejSGDx+Obdu2tVhmRUUFZsyYgbi4ONx///0oKCgwj8vJycGMGTOQmJiI8ePHY9euXeZxS5YswbPPPotZs2ZhyJAhOHLkSKu8RUVFmD17NhITE5GSkoKPP/4YQNNe1rJly3D8+HHExcVhzZo1rebdsGEDfHx88MorryA6OhpA0726li1bhv79+7ea/srvQ/P34t577wXQdBhtxYoVGD58OOLj4zFp0iScOXMGmzZtwo4dO5CVlYW4uDjMnj3bnPvxxx/HsGHDkJyc3KLY33jjDcyfPx+LFi3CTTfdhG3btiE7OxtTp07FTTfdhBEjRmDlypWt8pHz423kyWkMHDgQiYmJyMrKwhNPPGHx/NnZ2Zg2bRqOHDmCNWvW4Mknn8Qtt9yCffv24fvvvzc/zc7HxwcAsGPHDqxfvx6DBw/Gyy+/jEWLFmHjxo2ora3FI488gvnz5+Pdd9/Fb7/9hkceeQR9+/ZF3759AQA7d+7E+vXr8c4776CxsbFVlr/+9a/o06cP/ve//0GtVmPGjBmIiYnBtGnToFAosHnzZmzcuLHNr+Pbb79FSkpKp9yg8+uvv8YPP/yAPXv2wM/PD2q1Gn5+frjnnntw7NgxhIeHm7/XJpMJjz32GJKTk/Hqq6+iqKgIDz/8MHr27Gl+muOXX36JzMxMvPzyy2hoaMBDDz2EBx98EHfccQd0Oh3Onj1rdWZyPNwjIacyf/58fPjhhx16KE90dDTuvPNOKBQKTJw4ERqNBnPnzoW7uztGjhwJd3f3FoeGxowZg6FDh8Ld3R1PPPEEjh8/Do1Gg6+++gpRUVG48847oVQq8cc//hHjx4/Hnj17zPOOHTsW8fHxkMvlre5ppNFo8OOPP2LRokXw8PDAgAEDMG3aNGzfvr1dX0dlZSVCQ0Mt/vrbolQqodPpoFarIYoievfufdV7fJ08eRLl5eWYN28e3N3dERMTg7vvvrvF3tiQIUMwbtw4yOVyeHp6QqlU4vz58ygvL4ePjw+GDBnSKbnJsXCPhJzKDTfcgDFjxmD9+vXo3bu3RfMGBwebXzff5PLKJ/55eHi0eHZERESE+bWPjw/8/f1RXFyMgoICZGdnt3jAk9FoxO23325+f60nahYXF8Pf3x++vr7mYZGRkfj555/b9XUEBASY7+ZqreHDh2P69OnIyMiAIAhISUnB4sWLW2RrVlBQgOLi4lZf95Xvr/yeAU3PpFmzZg0mTJiA6OhozJs3D7fcckunZCfHwSIhpzN//nxMmTIFjzzyiHlY84np+vp680bQ2o1tYWGh+bVOp0NVVRXCwsKgUqkwdOhQbNiwoUPLDQsLQ1VVFWpqasxZNRoNwsPD2zX/8OHDsW/fPsybN69dh7e8vLxQV1dnfl9aWtpi/IMPPogHH3wQZWVlWLhwIf75z39i4cKFrR5FrFKpEB0djb179151Xb+fJzY2Fq+99hpMJhP27t2L+fPn48iRI516C3OSHg9tkdPp0aMHJk6ciA8++MA8LCgoCOHh4di+fTuMRiO2bNmCCxcuWLWegwcP4ocffkBDQwMyMzMxePBgqFQqjBkzBnl5efj000/R2NiIxsZGZGdnt/sBRiqVCnFxcXjttdeg1+tx+vRpbNmypd0PaJoxYwZ0Oh0WL15s/gBAUVERVq5cidOnT7eafsCAAdi3bx/q6uqQn5/f4iPF2dnZOHHiBBobG+Hl5QV3d3coFAoATXtwFy9eNE87aNAg+Pr6Yv369aivr4fRaMSZM2eQnZ191azbt29HeXk55HK5+dHBzcunroNFQk5p7ty5ra6ZWL58ObKyspCUlIRz584hLi7OqnWkpaXhrbfeQlJSEk6dOoVXXnkFAODr64usrCzs2rULo0aNwsiRI/GPf/wDDQ0N7V72a6+9hoKCAowaNQrz5s3D448/jj/96U/tmjcgIAAbN26EUqnE3Xffjbi4ODz00EPw8/Nr86FTDz30ENzc3DBixAgsXry4RWHpdDosW7YMiYmJuOWWWxAQEGDe07vrrrtw7tw5JCQkYM6cOVAoFFi7di1Onz6NsWPHYtiwYVi2bNk1H737v//9D7fddhvi4uLw4osvYvXq1Z36HAxyDHweCRERWYV7JEREZBUWCRERWYVFQkREVmGREBGRVVgkRERkFRYJERFZhUVCRERWYZEQEZFVWCRERGSV/wcHejUmNwh8BAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster_X = products.loc[:,['id', 'long', 'lat']]\n",
    "print(cluster_X)\n",
    "\n",
    "K_clusters = range(1,10)\n",
    "kmeans = [KMeans(n_clusters=i) for i in K_clusters]\n",
    "Y_axis = products[['lat']]\n",
    "X_axis = products[['long']]\n",
    "score = [kmeans[i].fit(Y_axis).score(Y_axis) for i in range(len(kmeans))]# Visualize\n",
    "plt.plot(K_clusters, score)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters = 3, init ='k-means++')\n",
    "kmeans.fit(cluster_X[cluster_X.columns[1:3]]) # Compute k-means clustering.\n",
    "cluster_X['cluster_long_lat'] = kmeans.fit_predict(cluster_X[cluster_X.columns[1:3]])\n",
    "centers = kmeans.cluster_centers_ # Coordinates of cluster centers.\n",
    "labels = kmeans.predict(cluster_X[cluster_X.columns[1:3]]) # Labels of each point\n",
    "\n",
    "cluster_X.plot.scatter(x = 'lat', y = 'long', c=labels, s=50, cmap='viridis')\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)\n",
    "cluster_X = cluster_X.drop(['long', 'lat'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_gbp</th>\n",
       "      <th>cat_0__Baby &amp; Kids Stuff</th>\n",
       "      <th>cat_0__Clothes, Footwear &amp; Accessories</th>\n",
       "      <th>cat_0__Computers &amp; Software</th>\n",
       "      <th>cat_0__DIY Tools &amp; Materials</th>\n",
       "      <th>cat_0__Health &amp; Beauty</th>\n",
       "      <th>cat_0__Home &amp; Garden</th>\n",
       "      <th>cat_0__Music, Films, Books &amp; Games</th>\n",
       "      <th>cat_0__Office Furniture &amp; Equipment</th>\n",
       "      <th>...</th>\n",
       "      <th>cat_1__ Washing Machines</th>\n",
       "      <th>cat_1__ Watches</th>\n",
       "      <th>cat_1__ Water Sports</th>\n",
       "      <th>cat_1__ Wedding Clothes &amp; Accessories</th>\n",
       "      <th>cat_1__ Winter Sports</th>\n",
       "      <th>cat_1__ Women's Accessories</th>\n",
       "      <th>cat_1__ Women's Clothing</th>\n",
       "      <th>cat_1__ Women's Shoes</th>\n",
       "      <th>cat_1__ Wood &amp; Timber</th>\n",
       "      <th>cluster_long_lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243809c0-9cfc-4486-ad12-3b7a16605ba9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1c58d3f9-8b93-47ea-9415-204fcc2a22e6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>860673f1-57f6-47ba-8d2f-13f9e05b8f9a</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59948726-29be-4b35-ade5-bb2fd7331856</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16dbc860-696e-4cda-93f6-4dd4926573fb</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6893</th>\n",
       "      <td>06d8a5c3-4f22-4d1b-ae7e-6ded471eb775</td>\n",
       "      <td>550.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6894</th>\n",
       "      <td>cce6d412-bac0-489e-9fba-cfdeeb756117</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6895</th>\n",
       "      <td>88d2d66b-2685-46b8-af84-f495fd2ccb14</td>\n",
       "      <td>380.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6896</th>\n",
       "      <td>8ca91ce8-49e7-4746-b06c-ac838d94ef35</td>\n",
       "      <td>650.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6897</th>\n",
       "      <td>df8ef910-03cc-4c9e-97a9-7f0a7e838102</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6898 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id  price_gbp  \\\n",
       "0     243809c0-9cfc-4486-ad12-3b7a16605ba9        5.0   \n",
       "1     1c58d3f9-8b93-47ea-9415-204fcc2a22e6       20.0   \n",
       "2     860673f1-57f6-47ba-8d2f-13f9e05b8f9a       20.0   \n",
       "3     59948726-29be-4b35-ade5-bb2fd7331856      115.0   \n",
       "4     16dbc860-696e-4cda-93f6-4dd4926573fb      450.0   \n",
       "...                                    ...        ...   \n",
       "6893  06d8a5c3-4f22-4d1b-ae7e-6ded471eb775      550.0   \n",
       "6894  cce6d412-bac0-489e-9fba-cfdeeb756117       69.0   \n",
       "6895  88d2d66b-2685-46b8-af84-f495fd2ccb14      380.0   \n",
       "6896  8ca91ce8-49e7-4746-b06c-ac838d94ef35      650.0   \n",
       "6897  df8ef910-03cc-4c9e-97a9-7f0a7e838102       10.0   \n",
       "\n",
       "      cat_0__Baby & Kids Stuff   cat_0__Clothes, Footwear & Accessories   \\\n",
       "0                             0                                        0   \n",
       "1                             0                                        0   \n",
       "2                             0                                        0   \n",
       "3                             0                                        0   \n",
       "4                             0                                        0   \n",
       "...                         ...                                      ...   \n",
       "6893                          0                                        0   \n",
       "6894                          0                                        0   \n",
       "6895                          0                                        0   \n",
       "6896                          0                                        0   \n",
       "6897                          0                                        0   \n",
       "\n",
       "      cat_0__Computers & Software   cat_0__DIY Tools & Materials   \\\n",
       "0                                0                              0   \n",
       "1                                0                              0   \n",
       "2                                0                              0   \n",
       "3                                0                              0   \n",
       "4                                0                              0   \n",
       "...                            ...                            ...   \n",
       "6893                             0                              0   \n",
       "6894                             0                              0   \n",
       "6895                             0                              0   \n",
       "6896                             0                              0   \n",
       "6897                             0                              0   \n",
       "\n",
       "      cat_0__Health & Beauty   cat_0__Home & Garden   \\\n",
       "0                           0                      1   \n",
       "1                           0                      1   \n",
       "2                           0                      1   \n",
       "3                           0                      1   \n",
       "4                           0                      1   \n",
       "...                       ...                    ...   \n",
       "6893                        0                      0   \n",
       "6894                        0                      0   \n",
       "6895                        0                      0   \n",
       "6896                        0                      0   \n",
       "6897                        0                      0   \n",
       "\n",
       "      cat_0__Music, Films, Books & Games   \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       0   \n",
       "3                                       0   \n",
       "4                                       0   \n",
       "...                                   ...   \n",
       "6893                                    0   \n",
       "6894                                    0   \n",
       "6895                                    0   \n",
       "6896                                    0   \n",
       "6897                                    0   \n",
       "\n",
       "      cat_0__Office Furniture & Equipment   ...  cat_1__ Washing Machines  \\\n",
       "0                                        0  ...                         0   \n",
       "1                                        0  ...                         0   \n",
       "2                                        0  ...                         0   \n",
       "3                                        0  ...                         0   \n",
       "4                                        0  ...                         0   \n",
       "...                                    ...  ...                       ...   \n",
       "6893                                     0  ...                         0   \n",
       "6894                                     0  ...                         0   \n",
       "6895                                     0  ...                         0   \n",
       "6896                                     0  ...                         0   \n",
       "6897                                     0  ...                         0   \n",
       "\n",
       "      cat_1__ Watches  cat_1__ Water Sports   \\\n",
       "0                   0                      0   \n",
       "1                   0                      0   \n",
       "2                   0                      0   \n",
       "3                   0                      0   \n",
       "4                   0                      0   \n",
       "...               ...                    ...   \n",
       "6893                0                      0   \n",
       "6894                0                      0   \n",
       "6895                0                      0   \n",
       "6896                0                      0   \n",
       "6897                0                      0   \n",
       "\n",
       "      cat_1__ Wedding Clothes & Accessories   cat_1__ Winter Sports   \\\n",
       "0                                          0                       0   \n",
       "1                                          0                       0   \n",
       "2                                          0                       0   \n",
       "3                                          0                       0   \n",
       "4                                          0                       0   \n",
       "...                                      ...                     ...   \n",
       "6893                                       0                       0   \n",
       "6894                                       0                       0   \n",
       "6895                                       0                       0   \n",
       "6896                                       0                       0   \n",
       "6897                                       0                       0   \n",
       "\n",
       "      cat_1__ Women's Accessories   cat_1__ Women's Clothing   \\\n",
       "0                                0                          0   \n",
       "1                                0                          0   \n",
       "2                                0                          0   \n",
       "3                                0                          0   \n",
       "4                                0                          0   \n",
       "...                            ...                        ...   \n",
       "6893                             0                          0   \n",
       "6894                             0                          0   \n",
       "6895                             0                          0   \n",
       "6896                             0                          0   \n",
       "6897                             0                          0   \n",
       "\n",
       "      cat_1__ Women's Shoes   cat_1__ Wood & Timber  cluster_long_lat  \n",
       "0                          0                      0                 0  \n",
       "1                          0                      0                 0  \n",
       "2                          0                      0                 0  \n",
       "3                          0                      0                 0  \n",
       "4                          0                      0                 0  \n",
       "...                      ...                    ...               ...  \n",
       "6893                       0                      0                 0  \n",
       "6894                       0                      0                 0  \n",
       "6895                       0                      0                 0  \n",
       "6896                       0                      0                 0  \n",
       "6897                       0                      0                 0  \n",
       "\n",
       "[6898 rows x 129 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_clustered = products.merge(cluster_X, left_on='id', right_on='id')\n",
    "products_clustered = products_clustered.drop(['long', 'lat'], axis=1)\n",
    "products_clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/adamw/Documents/AiCore/fb_marketplace/simple_models.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/adamw/Documents/AiCore/fb_marketplace/simple_models.ipynb#ch0000004?line=0'>1</a>\u001b[0m products_clustered \u001b[39m=\u001b[39m products_clustered\u001b[39m.\u001b[39;49mdrop([\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/adamw/Documents/AiCore/fb_marketplace/simple_models.ipynb#ch0000004?line=3'>4</a>\u001b[0m X \u001b[39m=\u001b[39m products_clustered\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mprice_gbp\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/adamw/Documents/AiCore/fb_marketplace/simple_models.ipynb#ch0000004?line=4'>5</a>\u001b[0m y \u001b[39m=\u001b[39m products_clustered[\u001b[39m'\u001b[39m\u001b[39mprice_gbp\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py:4948\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4799'>4800</a>\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4800'>4801</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4801'>4802</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4808'>4809</a>\u001b[0m     errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4809'>4810</a>\u001b[0m ):\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4810'>4811</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4811'>4812</a>\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4812'>4813</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4945'>4946</a>\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4946'>4947</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4947'>4948</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4948'>4949</a>\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4949'>4950</a>\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4950'>4951</a>\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4951'>4952</a>\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4952'>4953</a>\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4953'>4954</a>\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4954'>4955</a>\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/frame.py?line=4955'>4956</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/generic.py:4279\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/generic.py?line=4276'>4277</a>\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/generic.py?line=4277'>4278</a>\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/generic.py?line=4278'>4279</a>\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/generic.py?line=4280'>4281</a>\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/generic.py?line=4281'>4282</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/generic.py:4323\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/generic.py?line=4320'>4321</a>\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/generic.py?line=4321'>4322</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/generic.py?line=4322'>4323</a>\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/generic.py?line=4323'>4324</a>\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/generic.py?line=4325'>4326</a>\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/generic.py?line=4326'>4327</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/indexes/base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=6641'>6642</a>\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=6642'>6643</a>\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=6643'>6644</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=6644'>6645</a>\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   <a href='file:///home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=6645'>6646</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "products_clustered = products_clustered.drop(['id'], axis=1)\n",
    "\n",
    "\n",
    "X = products_clustered.drop(['price_gbp'], axis=1)\n",
    "y = products_clustered['price_gbp']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>cat_0__Baby &amp; Kids Stuff</th>\n",
       "      <th>cat_0__Clothes, Footwear &amp; Accessories</th>\n",
       "      <th>cat_0__Computers &amp; Software</th>\n",
       "      <th>cat_0__DIY Tools &amp; Materials</th>\n",
       "      <th>cat_0__Health &amp; Beauty</th>\n",
       "      <th>cat_0__Home &amp; Garden</th>\n",
       "      <th>cat_0__Music, Films, Books &amp; Games</th>\n",
       "      <th>cat_0__Office Furniture &amp; Equipment</th>\n",
       "      <th>...</th>\n",
       "      <th>cat_1__ Washer Dryers</th>\n",
       "      <th>cat_1__ Washing Machines</th>\n",
       "      <th>cat_1__ Watches</th>\n",
       "      <th>cat_1__ Water Sports</th>\n",
       "      <th>cat_1__ Wedding Clothes &amp; Accessories</th>\n",
       "      <th>cat_1__ Winter Sports</th>\n",
       "      <th>cat_1__ Women's Accessories</th>\n",
       "      <th>cat_1__ Women's Clothing</th>\n",
       "      <th>cat_1__ Women's Shoes</th>\n",
       "      <th>cat_1__ Wood &amp; Timber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.453489</td>\n",
       "      <td>-1.031873</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.479012</td>\n",
       "      <td>-4.225739</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.150228</td>\n",
       "      <td>0.329093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.291949</td>\n",
       "      <td>-2.447623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.568355</td>\n",
       "      <td>-2.026164</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7049</th>\n",
       "      <td>53.453547</td>\n",
       "      <td>-2.734323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7050</th>\n",
       "      <td>53.450693</td>\n",
       "      <td>-2.994883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7051</th>\n",
       "      <td>53.450693</td>\n",
       "      <td>-2.994883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7052</th>\n",
       "      <td>53.485152</td>\n",
       "      <td>-2.898906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7053</th>\n",
       "      <td>51.272337</td>\n",
       "      <td>-0.721647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6628 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           long       lat  cat_0__Baby & Kids Stuff   \\\n",
       "0     51.453489 -1.031873                          0   \n",
       "1     57.479012 -4.225739                          0   \n",
       "2     53.150228  0.329093                          0   \n",
       "3     51.291949 -2.447623                          0   \n",
       "4     53.568355 -2.026164                          0   \n",
       "...         ...       ...                        ...   \n",
       "7049  53.453547 -2.734323                          0   \n",
       "7050  53.450693 -2.994883                          0   \n",
       "7051  53.450693 -2.994883                          0   \n",
       "7052  53.485152 -2.898906                          0   \n",
       "7053  51.272337 -0.721647                          0   \n",
       "\n",
       "      cat_0__Clothes, Footwear & Accessories   cat_0__Computers & Software   \\\n",
       "0                                           0                             0   \n",
       "1                                           0                             0   \n",
       "2                                           0                             0   \n",
       "3                                           0                             0   \n",
       "4                                           0                             0   \n",
       "...                                       ...                           ...   \n",
       "7049                                        0                             0   \n",
       "7050                                        0                             0   \n",
       "7051                                        0                             0   \n",
       "7052                                        0                             0   \n",
       "7053                                        0                             0   \n",
       "\n",
       "      cat_0__DIY Tools & Materials   cat_0__Health & Beauty   \\\n",
       "0                                 0                        0   \n",
       "1                                 0                        0   \n",
       "2                                 0                        0   \n",
       "3                                 0                        0   \n",
       "4                                 0                        0   \n",
       "...                             ...                      ...   \n",
       "7049                              0                        0   \n",
       "7050                              0                        0   \n",
       "7051                              0                        0   \n",
       "7052                              0                        0   \n",
       "7053                              0                        0   \n",
       "\n",
       "      cat_0__Home & Garden   cat_0__Music, Films, Books & Games   \\\n",
       "0                         1                                    0   \n",
       "1                         1                                    0   \n",
       "2                         1                                    0   \n",
       "3                         1                                    0   \n",
       "4                         1                                    0   \n",
       "...                     ...                                  ...   \n",
       "7049                      0                                    0   \n",
       "7050                      0                                    0   \n",
       "7051                      0                                    0   \n",
       "7052                      0                                    0   \n",
       "7053                      0                                    0   \n",
       "\n",
       "      cat_0__Office Furniture & Equipment   ...  cat_1__ Washer Dryers  \\\n",
       "0                                        0  ...                      0   \n",
       "1                                        0  ...                      0   \n",
       "2                                        0  ...                      0   \n",
       "3                                        0  ...                      0   \n",
       "4                                        0  ...                      0   \n",
       "...                                    ...  ...                    ...   \n",
       "7049                                     0  ...                      0   \n",
       "7050                                     0  ...                      0   \n",
       "7051                                     0  ...                      0   \n",
       "7052                                     0  ...                      0   \n",
       "7053                                     0  ...                      0   \n",
       "\n",
       "      cat_1__ Washing Machines  cat_1__ Watches  cat_1__ Water Sports   \\\n",
       "0                            0                0                      0   \n",
       "1                            0                0                      0   \n",
       "2                            0                0                      0   \n",
       "3                            0                0                      0   \n",
       "4                            0                0                      0   \n",
       "...                        ...              ...                    ...   \n",
       "7049                         0                0                      0   \n",
       "7050                         0                0                      0   \n",
       "7051                         0                0                      0   \n",
       "7052                         0                0                      0   \n",
       "7053                         0                0                      0   \n",
       "\n",
       "      cat_1__ Wedding Clothes & Accessories   cat_1__ Winter Sports   \\\n",
       "0                                          0                       0   \n",
       "1                                          0                       0   \n",
       "2                                          0                       0   \n",
       "3                                          0                       0   \n",
       "4                                          0                       0   \n",
       "...                                      ...                     ...   \n",
       "7049                                       0                       0   \n",
       "7050                                       0                       0   \n",
       "7051                                       0                       0   \n",
       "7052                                       0                       0   \n",
       "7053                                       0                       0   \n",
       "\n",
       "      cat_1__ Women's Accessories   cat_1__ Women's Clothing   \\\n",
       "0                                0                          0   \n",
       "1                                0                          0   \n",
       "2                                0                          0   \n",
       "3                                0                          0   \n",
       "4                                0                          0   \n",
       "...                            ...                        ...   \n",
       "7049                             0                          0   \n",
       "7050                             0                          0   \n",
       "7051                             0                          0   \n",
       "7052                             0                          0   \n",
       "7053                             0                          0   \n",
       "\n",
       "      cat_1__ Women's Shoes   cat_1__ Wood & Timber  \n",
       "0                          0                      0  \n",
       "1                          0                      0  \n",
       "2                          0                      0  \n",
       "3                          0                      0  \n",
       "4                          0                      0  \n",
       "...                      ...                    ...  \n",
       "7049                       0                      0  \n",
       "7050                       0                      0  \n",
       "7051                       0                      0  \n",
       "7052                       0                      0  \n",
       "7053                       0                      0  \n",
       "\n",
       "[6628 rows x 128 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = products.drop(['id'], axis=1)\n",
    "\n",
    "\n",
    "X = products.drop(['price_gbp'], axis=1)\n",
    "y = products['price_gbp']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "lin = LinearRegression()\n",
    "# svr = SVR()\n",
    "lasso = Lasso(alpha=0.01, max_iter=100, selection='random')\n",
    "# elas = ElasticNet()\n",
    "dt = DecisionTreeRegressor(max_depth=5, max_features='auto', max_leaf_nodes=20,\n",
    "                      min_samples_leaf=8, min_weight_fraction_leaf=0.1)\n",
    "knn = KNeighborsRegressor(algorithm='kd_tree', leaf_size=10, n_neighbors=35, p=1)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01, max_depth=6, n_estimators=500,\n",
    "                          subsample=0.5)\n",
    "# sgd = SGDRegressor()\n",
    "# ker = KernelRidge()\n",
    "# bayes = BayesianRidge()\n",
    "\n",
    "regressor_dict = {\n",
    "    'Linear' : [lin],\n",
    "    'Lasso' : [lasso],\n",
    "    'DecisionTree' : [dt],\n",
    "    'KNeighbours' : [knn],\n",
    "    'GradientBoost' : [gbr],\n",
    "}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred.flatten()})\n",
    "# print(df.head())\n",
    "# print(np.mean(y_test))\n",
    "\n",
    "\n",
    "# save model weights\n",
    "# joblib.dump(lin_regression, \"linear_regression.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparamater tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler to train set - which means it identifies the values for scaling only on the training set and stores this in the scaler\n",
    "scaler.fit(X_train)\n",
    "# The scaler can now be applied to the train, validation and test sets which holds the info from the train set only\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_knn = {\n",
    "    'n_neighbors': [5, 35],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size': [10, 20, 30],\n",
    "    'p': [1, 2]\n",
    "    }\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    knn, \n",
    "    grid_knn, \n",
    "    cv=5,\n",
    "    verbose=2\n",
    "    )\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "gs.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must scale the independent varibles for a regularisation model like this.\n",
    "# https://towardsdatascience.com/hyperparameter-tuning-in-lasso-and-ridge-regressions-70a4b158ae6d\n",
    "# Consider using r2 \n",
    "# alphas = np.linspace(0, 0.2, 21)\n",
    "# print(alphas)\n",
    "\n",
    "grid_lasso = {\n",
    "    'alpha': [0.01],\n",
    "    'max_iter': [10, 10, 30, 40, 50, 70, 90, 100],\n",
    "    'selection': ['random'],\n",
    "    }\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    lasso, \n",
    "    grid_lasso, \n",
    "    cv=5,\n",
    "    verbose=2\n",
    "    )\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dt = {\n",
    "    \"splitter\":[\"best\",\"random\"],\n",
    "    \"max_depth\" : [5, 10],\n",
    "    \"min_samples_leaf\":[4, 5, 8, 9, 10],\n",
    "    \"min_weight_fraction_leaf\":[0.1,0.2],\n",
    "    \"max_features\":[\"auto\"],\n",
    "    \"max_leaf_nodes\":[20] \n",
    "    }\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    dt, \n",
    "    grid_dt, \n",
    "    cv=5,\n",
    "    verbose=2\n",
    "    )\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GrdientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, subsample=0.5; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, subsample=0.5; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, subsample=0.2; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, subsample=0.2; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, subsample=0.2; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, subsample=0.2; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, subsample=0.2; total time=   0.8s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, subsample=0.1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, subsample=0.1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, subsample=0.1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, subsample=0.1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=4, n_estimators=500, subsample=0.1; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.5; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.5; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.5; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.5; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.5; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.2; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.2; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.2; total time=   1.0s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.2; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.2; total time=   1.1s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.1; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.2s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.3s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.2s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.2s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.2s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=500, subsample=0.2; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=500, subsample=0.2; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=500, subsample=0.2; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=500, subsample=0.2; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=500, subsample=0.2; total time=   1.3s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=500, subsample=0.1; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=500, subsample=0.1; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=500, subsample=0.1; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=500, subsample=0.1; total time=   0.7s\n",
      "[CV] END learning_rate=0.01, max_depth=8, n_estimators=500, subsample=0.1; total time=   0.7s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=500, subsample=0.5; total time=   1.9s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=500, subsample=0.5; total time=   1.9s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=500, subsample=0.2; total time=   0.8s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=500, subsample=0.2; total time=   0.8s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=500, subsample=0.2; total time=   0.8s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=500, subsample=0.2; total time=   0.8s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=500, subsample=0.2; total time=   0.8s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=500, subsample=0.1; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=500, subsample=0.1; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=500, subsample=0.1; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=500, subsample=0.1; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=4, n_estimators=500, subsample=0.1; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, subsample=0.5; total time=   2.5s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, subsample=0.5; total time=   2.6s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, subsample=0.5; total time=   2.6s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, subsample=0.5; total time=   2.6s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, subsample=0.5; total time=   2.5s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, subsample=0.2; total time=   1.1s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, subsample=0.2; total time=   1.1s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, subsample=0.2; total time=   1.1s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, subsample=0.2; total time=   1.1s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, subsample=0.2; total time=   1.1s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, subsample=0.1; total time=   0.6s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, subsample=0.1; total time=   0.6s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, subsample=0.1; total time=   0.6s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, subsample=0.1; total time=   0.6s\n",
      "[CV] END learning_rate=0.02, max_depth=6, n_estimators=500, subsample=0.1; total time=   0.6s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.3s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.3s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.3s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.4s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.5s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=500, subsample=0.2; total time=   1.4s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=500, subsample=0.2; total time=   1.4s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=500, subsample=0.2; total time=   1.4s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=500, subsample=0.2; total time=   1.4s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=500, subsample=0.2; total time=   1.4s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=500, subsample=0.1; total time=   0.7s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=500, subsample=0.1; total time=   0.8s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=500, subsample=0.1; total time=   0.8s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=500, subsample=0.1; total time=   0.8s\n",
      "[CV] END learning_rate=0.02, max_depth=8, n_estimators=500, subsample=0.1; total time=   0.8s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=100, subsample=0.5; total time=   0.4s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=500, subsample=0.5; total time=   1.9s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=500, subsample=0.5; total time=   1.9s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=500, subsample=0.5; total time=   1.9s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=500, subsample=0.5; total time=   1.9s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=500, subsample=0.5; total time=   1.8s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=500, subsample=0.2; total time=   0.8s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=500, subsample=0.2; total time=   0.8s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=500, subsample=0.2; total time=   0.8s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=500, subsample=0.2; total time=   0.8s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=500, subsample=0.2; total time=   0.8s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=500, subsample=0.1; total time=   0.5s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=500, subsample=0.1; total time=   0.5s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=500, subsample=0.1; total time=   0.5s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=500, subsample=0.1; total time=   0.5s\n",
      "[CV] END learning_rate=0.03, max_depth=4, n_estimators=500, subsample=0.1; total time=   0.5s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=100, subsample=0.5; total time=   0.5s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=100, subsample=0.2; total time=   0.2s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=500, subsample=0.5; total time=   2.6s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=500, subsample=0.5; total time=   2.7s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=500, subsample=0.5; total time=   2.5s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=500, subsample=0.5; total time=   2.6s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=500, subsample=0.5; total time=   2.6s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=500, subsample=0.2; total time=   1.1s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=500, subsample=0.2; total time=   1.1s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=500, subsample=0.2; total time=   1.1s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=500, subsample=0.2; total time=   1.1s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=500, subsample=0.2; total time=   1.1s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=500, subsample=0.1; total time=   0.6s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=500, subsample=0.1; total time=   0.6s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=500, subsample=0.1; total time=   0.6s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=500, subsample=0.1; total time=   0.6s\n",
      "[CV] END learning_rate=0.03, max_depth=6, n_estimators=500, subsample=0.1; total time=   0.6s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.6s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=100, subsample=0.5; total time=   0.7s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=100, subsample=0.2; total time=   0.3s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=100, subsample=0.1; total time=   0.2s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=500, subsample=0.5; total time=   4.4s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.4s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.4s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.3s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=500, subsample=0.5; total time=   3.4s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=500, subsample=0.2; total time=   1.6s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=500, subsample=0.2; total time=   1.5s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=500, subsample=0.2; total time=   1.4s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=500, subsample=0.2; total time=   1.4s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=500, subsample=0.2; total time=   2.4s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=500, subsample=0.1; total time=   1.3s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=500, subsample=0.1; total time=   1.4s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=500, subsample=0.1; total time=   0.9s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=500, subsample=0.1; total time=   0.8s\n",
      "[CV] END learning_rate=0.03, max_depth=8, n_estimators=500, subsample=0.1; total time=   0.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, max_depth=6, n_estimators=500,\n",
       "                          subsample=0.5)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_gbr = {\n",
    "    'learning_rate': [0.01,0.02,0.03],\n",
    "    'subsample'    : [0.5, 0.2, 0.1],\n",
    "    'n_estimators' : [100,500],\n",
    "    'max_depth'    : [4,6,8]\n",
    "    }\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    gbr, \n",
    "    grid_gbr, \n",
    "    cv=5,\n",
    "    verbose=2\n",
    "    )\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[157.92115882 142.61368825 159.65134259 159.77340842 136.30888519\n",
      " 160.17735183 140.61373045 162.4471424  157.9658604  146.27734027\n",
      " 177.27935939 137.74270237 167.37114202 159.8628136  138.84743094\n",
      " 145.24414759 156.85135054 129.89196302 167.82417354 137.28230797\n",
      " 146.16891276 157.31902907 167.57458003 149.68944081 158.73580393\n",
      " 160.93025928 138.7066297  159.72718543 137.7429765  148.27270195]\n",
      "152.22716063526875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "# split\n",
    "# create scaler\n",
    "# fit scaler to train set - which means it identifies the values for scaling only on the training set and stores this in the scaler\n",
    "# The scaler can now be applied to the train, validation and test sets which holds the info from the train set only\n",
    "# the above is peromes using scaler.transform([dataset_name])\n",
    "\n",
    "# if using k fold validation\n",
    "mse_scorer = make_scorer(mean_squared_error)\n",
    "model = knn\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps= [\n",
    "        ('scaler', StandardScaler()), # is this scaling the target variable too? Will this impact output and MSE\n",
    "        ('model',  model)\n",
    "        ]\n",
    ")\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "# do i only put the train in or with cross validation it is OK to go with all\n",
    "#failing is it beucse im parsign a df and not an matrix\n",
    "scores = cross_val_score(pipe, X_train, y_train, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=1)\n",
    "scores = abs(scores)\n",
    "print(len(scores))\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run an assess models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No scaling or cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Linear model\n",
      "Mean Absolute Error: \n",
      " Test 102.14207390823681\n",
      "Mean Squared Error: \n",
      " Test 27123.34663594705\n",
      "Root Mean Squared Error: \n",
      " Test 164.6916714225314\n",
      "      Actual   Predicted\n",
      "4783    30.0   35.967773\n",
      "4662     5.0   20.959961\n",
      "4089     1.0   32.624023\n",
      "4965   150.0  272.327148\n",
      "4713    60.0  204.624023\n",
      "Training the Lasso model\n",
      "Mean Absolute Error: \n",
      " Test 102.12771252843028\n",
      "Mean Squared Error: \n",
      " Test 27116.987185352456\n",
      "Root Mean Squared Error: \n",
      " Test 164.67236314983901\n",
      "      Actual   Predicted\n",
      "4783    30.0   31.170155\n",
      "4662     5.0   20.292309\n",
      "4089     1.0   32.049758\n",
      "4965   150.0  272.863243\n",
      "4713    60.0  204.276196\n",
      "Training the DecisionTree model\n",
      "Mean Absolute Error: \n",
      " Test 121.42765891085537\n",
      "Mean Squared Error: \n",
      " Test 33687.90488564102\n",
      "Root Mean Squared Error: \n",
      " Test 183.5426514073528\n",
      "      Actual   Predicted\n",
      "4783    30.0   94.777509\n",
      "4662     5.0  136.923947\n",
      "4089     1.0  134.319266\n",
      "4965   150.0  134.319266\n",
      "4713    60.0  136.923947\n",
      "Training the KNeighbours model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.897e+07, tolerance: 1.579e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: \n",
      " Test 103.36077246283128\n",
      "Mean Squared Error: \n",
      " Test 27248.064650912856\n",
      "Root Mean Squared Error: \n",
      " Test 165.06987808474585\n",
      "      Actual   Predicted\n",
      "4783    30.0   16.824571\n",
      "4662     5.0  264.114286\n",
      "4089     1.0   10.028571\n",
      "4965   150.0  222.171429\n",
      "4713    60.0  196.599429\n",
      "Training the GradientBoost model\n",
      "Mean Absolute Error: \n",
      " Test 103.38019721959998\n",
      "Mean Squared Error: \n",
      " Test 27665.21872382287\n",
      "Root Mean Squared Error: \n",
      " Test 166.328646732374\n",
      "      Actual   Predicted\n",
      "4783    30.0   70.732218\n",
      "4662     5.0   53.097352\n",
      "4089     1.0   28.213481\n",
      "4965   150.0  209.545570\n",
      "4713    60.0  189.344754\n"
     ]
    }
   ],
   "source": [
    "for model in regressor_dict:\n",
    "    print(f'Training the {model} model')\n",
    "    regressor_dict[model][0].fit(X_train, y_train)\n",
    "    y_pred = regressor_dict[model][0].predict(X_test)\n",
    "    y_pred_train = regressor_dict[model][0].predict(X_train)\n",
    "    print('Mean Absolute Error: \\n Test', metrics.mean_absolute_error(y_test, y_pred) )\n",
    "    # print('Train', metrics.mean_absolute_error(y_train, y_pred_train))  \n",
    "    print('Mean Squared Error: \\n Test', metrics.mean_squared_error(y_test, y_pred))  \n",
    "    # print('Train', metrics.mean_squared_error(y_train, y_pred_train))\n",
    "    print('Root Mean Squared Error: \\n Test', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    # print('Train', np.sqrt(metrics.mean_squared_error(y_train, y_pred_train)))\n",
    "    df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred.flatten()})\n",
    "    print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling without cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Linear model\n",
      "Mean Absolute Error: \n",
      " Test 102.14207390823681\n",
      "Mean Squared Error: \n",
      " Test 27123.34663594705\n",
      "Root Mean Squared Error: \n",
      " Test 164.6916714225314\n",
      "      Actual   Predicted\n",
      "4783    30.0   35.967773\n",
      "4662     5.0   20.959961\n",
      "4089     1.0   32.624023\n",
      "4965   150.0  272.327148\n",
      "4713    60.0  204.624023\n",
      "Training the KNeighbours model\n",
      "Mean Absolute Error: \n",
      " Test 101.11288084464555\n",
      "Mean Squared Error: \n",
      " Test 29496.97488751131\n",
      "Root Mean Squared Error: \n",
      " Test 171.74683370447127\n",
      "      Actual  Predicted\n",
      "4783    30.0     27.286\n",
      "4662     5.0     18.000\n",
      "4089     1.0      1.000\n",
      "4965   150.0    123.200\n",
      "4713    60.0    247.798\n",
      "Training the KNeighbours_Optimised model\n",
      "Mean Absolute Error: \n",
      " Test 103.36077246283128\n",
      "Mean Squared Error: \n",
      " Test 27248.064650912856\n",
      "Root Mean Squared Error: \n",
      " Test 165.06987808474585\n",
      "      Actual   Predicted\n",
      "4783    30.0   16.824571\n",
      "4662     5.0  264.114286\n",
      "4089     1.0   10.028571\n",
      "4965   150.0  222.171429\n",
      "4713    60.0  196.599429\n"
     ]
    }
   ],
   "source": [
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler to train set - which means it identifies the values for scaling only on the training set and stores this in the scaler\n",
    "scaler.fit(X_train)\n",
    "# The scaler can now be applied to the train, validation and test sets which holds the info from the train set only\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# the above is peromes using scaler.transform([dataset_name])\n",
    "for model in regressor_dict:\n",
    "    print(f'Training the {model} model')\n",
    "    regressor_dict[model][0].fit(X_train, y_train)\n",
    "    y_pred = regressor_dict[model][0].predict(X_test)\n",
    "    y_pred_train = regressor_dict[model][0].predict(X_train)\n",
    "    print('Mean Absolute Error: \\n Test', metrics.mean_absolute_error(y_test, y_pred) )\n",
    "    # print('Train', metrics.mean_absolute_error(y_train, y_pred_train))  \n",
    "    print('Mean Squared Error: \\n Test', metrics.mean_squared_error(y_test, y_pred))  \n",
    "    # print('Train', metrics.mean_squared_error(y_train, y_pred_train))\n",
    "    print('Root Mean Squared Error: \\n Test', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    # print('Train', np.sqrt(metrics.mean_squared_error(y_train, y_pred_train)))\n",
    "    df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred.flatten()})\n",
    "    print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Linear model\n",
      "30\n",
      "[2.51600379e+14 1.43499085e+02 4.46236720e+11 1.59273996e+02\n",
      " 1.94433317e+13 1.54912901e+02 1.41013178e+02 1.59946148e+02\n",
      " 1.60186482e+02 2.10760735e+12 1.74727677e+02 1.42520635e+02\n",
      " 1.66226227e+02 8.54193509e+14 9.41180355e+12 1.51494473e+02\n",
      " 1.57803361e+02 1.29698881e+02 1.67997305e+02 1.57133638e+14\n",
      " 3.94278363e+14 1.48206286e+02 1.75624404e+02 8.10018191e+13\n",
      " 1.58237794e+02 1.59125806e+02 1.42904373e+02 2.49331597e+14\n",
      " 7.01735454e+13 1.49794962e+02]\n",
      "69637394346105.25\n",
      "Training the Lasso model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.603e+07, tolerance: 1.404e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.840e+07, tolerance: 1.439e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.562e+07, tolerance: 1.400e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.381e+07, tolerance: 1.399e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.297e+07, tolerance: 1.460e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e+07, tolerance: 1.424e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e+07, tolerance: 1.445e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.932e+07, tolerance: 1.416e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.252e+07, tolerance: 1.405e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.490e+07, tolerance: 1.421e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.823e+07, tolerance: 1.363e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.091e+07, tolerance: 1.430e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.444e+07, tolerance: 1.395e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.864e+07, tolerance: 1.404e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.167e+07, tolerance: 1.460e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.252e+07, tolerance: 1.431e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.171e+07, tolerance: 1.420e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.220e+07, tolerance: 1.472e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.967e+07, tolerance: 1.395e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.308e+07, tolerance: 1.441e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.299e+07, tolerance: 1.417e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.563e+07, tolerance: 1.428e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.754e+07, tolerance: 1.388e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.718e+07, tolerance: 1.428e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.203e+07, tolerance: 1.407e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.841e+07, tolerance: 1.417e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.220e+07, tolerance: 1.444e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.814e+07, tolerance: 1.413e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.062e+07, tolerance: 1.451e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/adamw/miniconda3/envs/fb_marketplace/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.142e+07, tolerance: 1.420e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[157.04606031 143.45953383 162.85568419 158.68585355 129.87972438\n",
      " 154.94837174 140.92387679 159.84410877 159.92988351 151.1249997\n",
      " 174.73123062 141.80244267 165.82641349 163.10238425 132.62411876\n",
      " 150.50106188 157.73092691 129.64968437 167.81797923 134.39191633\n",
      " 146.151811   148.21256101 175.45750229 151.68030289 157.98065273\n",
      " 159.03925431 140.99457776 157.49385402 135.02037709 148.49085101]\n",
      "151.9132666457949\n",
      "Training the DecisionTree model\n",
      "30\n",
      "[181.73259863 162.74946391 182.64800933 182.65628043 147.92569729\n",
      " 170.37054683 159.91336336 174.72777427 180.95132527 170.54130993\n",
      " 200.71104248 167.11959437 186.26637546 179.24709327 150.83781612\n",
      " 167.29144115 171.13225986 141.68504328 185.94205838 161.77765798\n",
      " 173.03736749 165.95406265 187.65672679 167.87969828 180.48830546\n",
      " 174.91558899 160.31874704 177.71496024 154.59063874 172.37887458]\n",
      "171.37205739566875\n",
      "Training the KNeighbours model\n",
      "30\n",
      "[157.92115882 142.61368825 159.65134259 159.77340842 136.30888519\n",
      " 160.17735183 140.61373045 162.4471424  157.9658604  146.27734027\n",
      " 177.27935939 137.74270237 167.37114202 159.8628136  138.84743094\n",
      " 145.24414759 156.85135054 129.89196302 167.82417354 137.28230797\n",
      " 146.16891276 157.31902907 167.57458003 149.68944081 158.73580393\n",
      " 160.93025928 138.7066297  159.72718543 137.7429765  148.27270195]\n",
      "152.22716063526875\n",
      "Training the GradientBoost model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for model in regressor_dict:\n",
    "    print(f'Training the {model} model')\n",
    "    model = regressor_dict[model][0]\n",
    "    pipe = Pipeline(\n",
    "    steps= [\n",
    "        ('scaler', StandardScaler()), # is this scaling the target variable too? Will this impact output and MSE\n",
    "        ('model',  model)\n",
    "        ]\n",
    "    )\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "    # do i only put the train in or with cross validation it is OK to go with all\n",
    "    #failing is it beucse im parsign a df and not an matrix\n",
    "    scores = cross_val_score(pipe, X_train, y_train, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=1)\n",
    "    scores = abs(scores)\n",
    "    print(len(scores))\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ad305deca811d2df6c57b148dec1e835d783e41823b85ed7281e336135b66d8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('fb_marketplace')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
