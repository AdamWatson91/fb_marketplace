{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import json\n",
    "from pandas_profiling import ProfileReport\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from skimage.filters import try_all_threshold\n",
    "from skimage.filters import threshold_local\n",
    "from skimage.feature import canny\n",
    "from skimage.exposure import equalize_hist\n",
    "from skimage.exposure import equalize_adapthist\n",
    "from skimage.segmentation import slic\n",
    "from skimage.measure import find_contours\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "from skimage.feature import corner_harris\n",
    "from skimage.feature import corner_peaks\n",
    "\n",
    "\n",
    "\n",
    "# Get database connection credentials\n",
    "with open(os.path.join(os.getcwd(),'fb_marketplace_conn.json'), mode='r') as f:\n",
    "    database_dict = json.load(f)\n",
    "# Password for the database\n",
    "RDS_pass = 'aicore2022!'\n",
    "# Create engine to connect to database\n",
    "engine = create_engine(f\"{database_dict['DATABASE_TYPE']}+{database_dict['DBAPI']}://{database_dict['USER']}:{RDS_pass}@{database_dict['HOST']}:{database_dict['PORT']}/{database_dict['DATABASE']}\")\n",
    "# Import the tables as DataFrame\n",
    "images = pd.read_sql('images', engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = ProfileReport(images)\n",
    "prof.to_file(output_file='images.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image cleansing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2020/10/create-image-classification-model-python-keras/\n",
    "def show(image: np.ndarray, title=\"Image\", cmap_type=\"gray\", axis=False):\n",
    "    \"\"\"\n",
    "    A function to display np.ndarrays as images\n",
    "    \"\"\"\n",
    "    plt.imshow(image, cmap=cmap_type)\n",
    "    plt.title(title)\n",
    "    if not axis:\n",
    "        plt.axis(\"off\")\n",
    "    plt.margins(0, 0)\n",
    "    plt.show()\n",
    "\n",
    "def mark_contours(image):\n",
    "    \"\"\"A function to find contours from an image\"\"\"\n",
    "    gray_image = rgb2gray(image)\n",
    "    # Find optimal threshold\n",
    "    thresh = threshold_otsu(gray_image)\n",
    "    # Mask\n",
    "    binary_image = gray_image > thresh\n",
    "\n",
    "    contours = find_contours(binary_image)\n",
    "\n",
    "    return contours\n",
    "    \n",
    "def plot_image_contours(image):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.imshow(image, cmap=plt.cm.gray)\n",
    "\n",
    "    for contour in mark_contours(image):\n",
    "        ax.plot(contour[:, 1], contour[:, 0], linewidth=2, color=\"red\")\n",
    "\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "def plot_with_hist_channel(image, channel):\n",
    "    \"\"\"\n",
    "    Histogram of color channels\n",
    "    \"\"\"\n",
    "    channels = [\"red\", \"green\", \"blue\"]\n",
    "    channel_idx = channels.index(channel)\n",
    "    color = channels[channel_idx]\n",
    "    extracted_channel = image[:, :, channel_idx]\n",
    "    fig, (ax1, ax2) = plt.subplots(\n",
    "        ncols=2, figsize=(18, 6)\n",
    "    )\n",
    "    ax1.imshow(image)\n",
    "    ax1.axis(\"off\")\n",
    "    ax2.hist(extracted_channel.ravel(), bins=256, color=color)\n",
    "    ax2.set_title(f\"{channels[channel_idx]} histogram\")\n",
    "\n",
    "def resize_image(image: Image, length: int) -> Image:\n",
    "    \"\"\"\n",
    "    Resize an image to a square. Can make an image bigger to make it fit or smaller if it doesn't fit. It also crops\n",
    "    part of the image.\n",
    "    https://stackoverflow.com/questions/43512615/reshaping-rectangular-image-to-square\n",
    "\n",
    "    :param self:\n",
    "    :param image: Image to resize.\n",
    "    :param length: Width and height of the output image.\n",
    "    :return: Return the resized image.\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Resizing strategy : \n",
    "     1) We resize the smallest side to the desired dimension (e.g. 1080)\n",
    "     2) We crop the other side so as to make it fit with the same length as the smallest side (e.g. 1080)\n",
    "    \"\"\"\n",
    "    if image.size[0] < image.size[1]:\n",
    "        # The image is in portrait mode. Height is bigger than width.\n",
    "\n",
    "        # This makes the width fit the LENGTH in pixels while conserving the ration.\n",
    "        resized_image = image.resize((length, int(image.size[1] * (length / image.size[0]))))\n",
    "\n",
    "        # Amount of pixel to lose in total on the height of the image.\n",
    "        required_loss = (resized_image.size[1] - length)\n",
    "\n",
    "        # Crop the height of the image so as to keep the center part.\n",
    "        resized_image = resized_image.crop(\n",
    "            box=(0, required_loss / 2, length, resized_image.size[1] - required_loss / 2))\n",
    "\n",
    "        # We now have a length*length pixels image.\n",
    "        return resized_image\n",
    "    else:\n",
    "        # This image is in landscape mode or already squared. The width is bigger than the heihgt.\n",
    "\n",
    "        # This makes the height fit the LENGTH in pixels while conserving the ration.\n",
    "        resized_image = image.resize((int(image.size[0] * (length / image.size[1])), length))\n",
    "\n",
    "        # Amount of pixel to lose in total on the width of the image.\n",
    "        required_loss = resized_image.size[0] - length\n",
    "\n",
    "        # Crop the width of the image so as to keep 1080 pixels of the center part.\n",
    "        resized_image = resized_image.crop(\n",
    "            box=(required_loss / 2, 0, resized_image.size[0] - required_loss / 2, length))\n",
    "\n",
    "        # We now have a length*length pixels image.\n",
    "        return resized_image\n",
    "    \n",
    "\n",
    "        \n",
    "    def compare(original, filtered, title_filtered=\"Filtered\", cmap_type=\"gray\", axis=False, title_original=\"Original\"):\n",
    "        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 8), sharex=True, sharey=True)\n",
    "        ax1.imshow(original, cmap=cmap_type)\n",
    "        ax1.set_title(title_original)\n",
    "\n",
    "        ax2.imshow(filtered, cmap=cmap_type)\n",
    "        ax2.set_title(title_filtered)\n",
    "\n",
    "        if not axis:\n",
    "            ax1.axis(\"off\")\n",
    "            ax2.axis(\"off\")\n",
    "        plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0.01)\n",
    "        plt.margins(0, 0)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_path = os.path.join(os.getcwd(),'images_fb/images/','0a1d0925-d2aa-4e89-b9d3-ef56b834cfd9.jpg')\n",
    "img = Image.open(image_path)\n",
    "# Image name\n",
    "img_filename = img.filename\n",
    "# Image format e.g. JPRG\n",
    "img_format = img.format\n",
    "# Image mode e.g. RGB\n",
    "img_mode = img.mode\n",
    "# Image size as tupe (width, height)\n",
    "img_size = img.size\n",
    "# Image info - a dictionary wiht image info\n",
    "img_info = img.info\n",
    "print(img_info)\n",
    "# Convert to numpy array\n",
    "img2arr = array(img)\n",
    "print(img2arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Planned for data preparation\n",
    "Notes for consideration for later:\n",
    "- Image data should probably be centered by subtracting the per-channel mean pixel values calculated on the training dataset.\n",
    "- Training data augmentation should probably involve random rescaling, horizontal flips, perturbations to brightness, contrast and color, as well as random cropping.\n",
    "- Test-time augmentation should probably involve both a mixture of multiple rescaling of each image as well as predictions for multiple different systematic crops of each rescaled version of the image.\n",
    "\n",
    "https://towardsdatascience.com/massive-tutorial-on-image-processing-and-preparation-for-deep-learning-in-python-1-e534ee42f122\n",
    "https://machinelearningmastery.com/start-here/#dlfcv - nice overall guide to managing images\n",
    "https://machinelearningmastery.com/deep-learning-for-computer-vision/ - a book for computer vision\n",
    "https://machinelearningmastery.com/how-to-load-and-manipulate-images-for-deep-learning-in-python-with-pil-pillow/ - sing pillow\n",
    "https://machinelearningmastery.com/best-practices-for-preparing-and-augmenting-image-data-for-convolutional-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/adamw/Documents/AiCore/fb_marketplace/clean_images.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/adamw/Documents/AiCore/fb_marketplace/clean_images.ipynb#ch0000009?line=6'>7</a>\u001b[0m img_list \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/adamw/Documents/AiCore/fb_marketplace/clean_images.ipynb#ch0000009?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(download_image_directory):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/adamw/Documents/AiCore/fb_marketplace/clean_images.ipynb#ch0000009?line=8'>9</a>\u001b[0m         \u001b[39m# get image\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/adamw/Documents/AiCore/fb_marketplace/clean_images.ipynb#ch0000009?line=9'>10</a>\u001b[0m         img \u001b[39m=\u001b[39mImage\u001b[39m.\u001b[39mopen(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(download_image_directory,file))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adamw/Documents/AiCore/fb_marketplace/clean_images.ipynb#ch0000009?line=10'>11</a>\u001b[0m         \u001b[39mif\u001b[39;00m img\u001b[39m.\u001b[39mheight \u001b[39m==\u001b[39m img\u001b[39m.\u001b[39mwidth:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adamw/Documents/AiCore/fb_marketplace/clean_images.ipynb#ch0000009?line=11'>12</a>\u001b[0m             \u001b[39m# square images to 256 x 256\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adamw/Documents/AiCore/fb_marketplace/clean_images.ipynb#ch0000009?line=12'>13</a>\u001b[0m             img\u001b[39m.\u001b[39mresize(\u001b[39m256\u001b[39m,\u001b[39m256\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "# Get all images file names  - for now play with first 100\n",
    "# example of global centering (subtract mean)\n",
    "\n",
    "\n",
    "download_image_directory = os.path.join(os.getcwd(),'images_fb/test_images/')\n",
    "upload_image_directory = os.path.join(os.getcwd(),'images_fb/cleaned_test_images/')\n",
    "img_list = []\n",
    "for file in os.listdir(download_image_directory):\n",
    "        # get image\n",
    "        img =Image.open(os.path.join(download_image_directory,file))\n",
    "        if img.height == img.width:\n",
    "            # square images to 256 x 256\n",
    "            img.resize(256,256)\n",
    "        else:\n",
    "            # rectangle images to 256 on shortest size then the middle 256 x 256 sqaure crop\n",
    "            img = resize_image(img, 256)\n",
    "        colour_img = img\n",
    "        colour_img_array = np.asarray(colour_img)\n",
    "        # Consider converting to greyscale\n",
    "        img = img.convert(mode='L')\n",
    "        # Normalise the data - scaling pixel values to the range 0-1\n",
    "        img_array = asarray(img)\n",
    "        pixels = img_array.astype('float32')\n",
    "        pixel_mean = pixels.mean()\n",
    "        print(f'pixel mean is {pixel_mean}')\n",
    "        print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\n",
    "        normalise_array = pixels\n",
    "        normalise_array /= 255\n",
    "        # Consider thresholding to get better image definition - consider a check whther threshold or type of threshold to use per image\n",
    "        # Manual Global threshold\n",
    "        threshold = normalise_array.mean()\n",
    "        binary_array = normalise_array > threshold\n",
    "        binary_image = Image.fromarray(binary_array)\n",
    "        # Review algorithm based global threshold - looks like mean was best across them but different images are goign to benefit in different ways\n",
    "        fig, ax = try_all_threshold(img_array, figsize=(10, 8), verbose=False)\n",
    "        # Local threshold algorithims\n",
    "        local_thresh = threshold_local(img_array, block_size=5, offset=2.000)\n",
    "        local_binary = img_array > local_thresh\n",
    "        local_binary_img = Image.fromarray(local_binary)\n",
    "        # local_binary_img.show()\n",
    "        # Edge detection\n",
    "        product_edge = canny(img_array, sigma=1)\n",
    "        product_edge = Image.fromarray(product_edge)\n",
    "        product_edge.show()\n",
    "\n",
    "        # image contrast enhancement - NOT WORKING\n",
    "        img_contrast = img_array.max() - img_array.min()\n",
    "        print(f'image_contrast is {img_contrast}')\n",
    "        enhanced = equalize_adapthist(img_array, clip_limit=0.4)\n",
    "        enhanced = Image.fromarray(enhanced)\n",
    "\n",
    "\n",
    "        # image segmentation - NOT WORKING\n",
    "        segments = slic(colour_img_array, n_segments=100)\n",
    "        segments = Image.fromarray(segments, mode='L')\n",
    "\n",
    "\n",
    "        # image contours\n",
    "\n",
    "        denoise_colour_array = denoise_tv_chambolle(colour_img_array, channel_axis=True)\n",
    "        print(denoise_colour_array)\n",
    "        # plot_image_contours(denoise_colour_array)\n",
    "        # plot_image_contours(colour_img_array)\n",
    "\n",
    "        # corner detection\n",
    "        measured_img = corner_harris(img_array)\n",
    "        show(measured_img)\n",
    "        denoise_gray_array = denoise_tv_chambolle(img_array, channel_axis=True, weight=0.3)\n",
    "        corner_coords = corner_peaks(denoise_gray_array, min_distance=40)\n",
    "        print(len(corner_coords))\n",
    "        plt.imshow(img_array, cmap=\"gray\")\n",
    "        plt.plot(corner_coords[:, 1], corner_coords[:, 0], \"+b\", markersize=15)\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # could have different version of the image and use the oerall score ?\n",
    "\n",
    "        # Consider a function that allows user to pick whther to centre pre or post normalisation with normalised yes/no\n",
    "        # Centre prior to normalisation \n",
    "        global_centered = pixels\n",
    "        global_centered = global_centered - pixel_mean\n",
    "        global_centered = global_centered.mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Centre post normalisation\n",
    "\n",
    "        # plt.hist(img_array.ravel(), bins=256)\n",
    "        # plt.show()\n",
    "\n",
    "        # build list of  cleaned images\n",
    "        # img_list.append(img)\n",
    "\n",
    "        # save the cleaned images\n",
    "        # check does this replace\n",
    "        # img.save(os.path.join(upload_image_directory,file), format='JPEG')\n",
    "        # binary_image.save(os.path.join(upload_image_directory,'binary_'+file), format='JPEG')\n",
    "# print(img_list)\n",
    "\n",
    "\n",
    "# img_array_list = asarray(img_list)\n",
    "# print(img_array_list)\n",
    "\n",
    "# img_array_list = [array(Image.open(file)) for file in os.listdir(image_directory)]\n",
    "# print(img_array_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/\n",
    "\n",
    "# center pixel values both globally across channels and locally per channel\n",
    "# standardize pixel values and how to shift standardized pixel values to the positive domain.\n",
    "# Consider data augmentation - i.e. changign data structure like rotaing etc. to give the model more to train"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ad305deca811d2df6c57b148dec1e835d783e41823b85ed7281e336135b66d8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('fb_marketplace')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
